
<!DOCTYPE html>


<html lang="en" data-theme="light">

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>pyxu_diffops.operator.diffusion.diffusion &#8212; pyxu-diffops Documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "light";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-codeautolink.css?v=b2176991" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/css/custom.css?v=113f4227" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script src="../../../../_static/documentation_options.js?v=3a322c97"></script>
    <script src="../../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../../_static/copybutton.js?v=30646c52"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script src="../../../../_static/design-tabs.js?v=f930bc37"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/pyxu_diffops/operator/diffusion/diffusion';</script>
    <link rel="icon" href="../../../../_static/favicon.png"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="light">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
<div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
    <span class="fa-solid fa-bars"></span>
  </label>
  
  <div class="navbar-header-items__start">
    
      <div class="navbar-item">
  

<a class="navbar-brand logo" href="../../../../index.html">
  
  
  
  
    
    
    
    <img src="../../../../_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../../../../_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
    
  </div>
  
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../../api/index.html">
                        API Reference
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../../examples/index.html">
                        Example Gallery
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../../references.html">
                        References
                      </a>
                    </li>
                
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          
<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
        </div>
      
      
        <div class="navbar-item">
<strong> v1.0b1 </strong></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links navbar-nav"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/dhamm97/pyxu-diffops" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-github"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/dhamm97/pyxu-diffops" title="PyPI" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-python"></i></span>
            <label class="sr-only">PyPI</label></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="mailto: daniele.hamm@epfl.ch" title="Contact" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class=""></i></span>
            <label class="sr-only">Contact</label></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">
<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
    </div>
  

  
    <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
    </label>
  
</div>

    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../../api/index.html">
                        API Reference
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../../examples/index.html">
                        Example Gallery
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../../references.html">
                        References
                      </a>
                    </li>
                
  </ul>
</nav></div>
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<strong> v1.0b1 </strong></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links navbar-nav"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/dhamm97/pyxu-diffops" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-github"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/dhamm97/pyxu-diffops" title="PyPI" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-python"></i></span>
            <label class="sr-only">PyPI</label></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="mailto: daniele.hamm@epfl.ch" title="Contact" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class=""></i></span>
            <label class="sr-only">Contact</label></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumbs">
  <ul class="bd-breadcrumbs" role="navigation" aria-label="Breadcrumb">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../../index.html" class="nav-link">Module code</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">pyxu_diffops.operator.diffusion.diffusion</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <h1>Source code for pyxu_diffops.operator.diffusion.diffusion</h1><div class="highlight"><pre>
<span></span><span class="linenos">   1</span><span class="kn">import</span><span class="w"> </span><span class="nn">collections.abc</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">cabc</span>
<span class="linenos">   2</span><span class="kn">import</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">typ</span>
<span class="linenos">   3</span>
<span class="linenos">   4</span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="linenos">   5</span><span class="kn">import</span><span class="w"> </span><span class="nn">pyxu.info.ptype</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pyct</span>
<span class="linenos">   6</span><span class="kn">import</span><span class="w"> </span><span class="nn">pyxu.operator.linop.diff</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pydiff</span>
<span class="linenos">   7</span><span class="kn">import</span><span class="w"> </span><span class="nn">pyxu.operator.linop.filter</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pyfilt</span>
<span class="linenos">   8</span><span class="kn">import</span><span class="w"> </span><span class="nn">pyxu.util</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pycu</span>
<span class="linenos">   9</span>
<span class="linenos">  10</span><span class="kn">from</span><span class="w"> </span><span class="nn">pyxu_diffops.operator.diffusion._diffusion</span><span class="w"> </span><span class="kn">import</span> <span class="n">_Diffusion</span>
<span class="linenos">  11</span><span class="kn">from</span><span class="w"> </span><span class="nn">pyxu_diffops.operator.diffusion._diffusion_coeff</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
<span class="linenos">  12</span>    <span class="n">DiffusionCoeffAnisoCoherenceEnhancing</span><span class="p">,</span>
<span class="linenos">  13</span>    <span class="n">DiffusionCoeffAnisoEdgeEnhancing</span><span class="p">,</span>
<span class="linenos">  14</span>    <span class="n">DiffusionCoeffAnisotropic</span><span class="p">,</span>
<span class="linenos">  15</span>    <span class="n">DiffusionCoeffIsotropic</span><span class="p">,</span>
<span class="linenos">  16</span>    <span class="n">_DiffusionCoefficient</span><span class="p">,</span>
<span class="linenos">  17</span><span class="p">)</span>
<span class="linenos">  18</span><span class="kn">from</span><span class="w"> </span><span class="nn">pyxu_diffops.operator.diffusion._diffusivity</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
<span class="linenos">  19</span>    <span class="n">MfiDiffusivity</span><span class="p">,</span>
<span class="linenos">  20</span>    <span class="n">PeronaMalikDiffusivity</span><span class="p">,</span>
<span class="linenos">  21</span>    <span class="n">TotalVariationDiffusivity</span><span class="p">,</span>
<span class="linenos">  22</span><span class="p">)</span>
<span class="linenos">  23</span><span class="kn">from</span><span class="w"> </span><span class="nn">pyxu_diffops.operator.diffusion._extra_diffusion_term</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
<span class="linenos">  24</span>    <span class="n">CurvaturePreservingTerm</span><span class="p">,</span>
<span class="linenos">  25</span>    <span class="n">MfiExtraTerm</span><span class="p">,</span>
<span class="linenos">  26</span><span class="p">)</span>
<span class="linenos">  27</span>
<span class="linenos">  28</span><span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
<span class="linenos">  29</span>    <span class="s2">&quot;MfiDiffusion&quot;</span><span class="p">,</span>
<span class="linenos">  30</span>    <span class="s2">&quot;PeronaMalikDiffusion&quot;</span><span class="p">,</span>
<span class="linenos">  31</span>    <span class="s2">&quot;TikhonovDiffusion&quot;</span><span class="p">,</span>
<span class="linenos">  32</span>    <span class="s2">&quot;TotalVariationDiffusion&quot;</span><span class="p">,</span>
<span class="linenos">  33</span>    <span class="s2">&quot;CurvaturePreservingDiffusionOp&quot;</span><span class="p">,</span>
<span class="linenos">  34</span>    <span class="s2">&quot;AnisEdgeEnhancingDiffusionOp&quot;</span><span class="p">,</span>
<span class="linenos">  35</span>    <span class="s2">&quot;AnisCoherenceEnhancingDiffusionOp&quot;</span><span class="p">,</span>
<span class="linenos">  36</span>    <span class="s2">&quot;AnisDiffusionOp&quot;</span><span class="p">,</span>
<span class="linenos">  37</span><span class="p">]</span>
<span class="linenos">  38</span><span class="c1"># &quot;AnisMfiDiffusionOp&quot;]</span>
<span class="linenos">  39</span>
<span class="linenos">  40</span><span class="c1"># pxa.LinOp</span>
<span class="linenos">  41</span>
<span class="linenos">  42</span>
<div class="viewcode-block" id="MfiDiffusion">
<a class="viewcode-back" href="../../../../api/operator.html#pyxu_diffops.operator.MfiDiffusion">[docs]</a>
<span class="linenos">  43</span><span class="k">class</span><span class="w"> </span><span class="nc">MfiDiffusion</span><span class="p">(</span><span class="n">_Diffusion</span><span class="p">):</span>
<span class="linenos">  44</span><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="linenos">  45</span><span class="sd">    Minimum Fisher Information (MFI) diffusion operator, featuring an inhomogeneous isotropic diffusion tensor.</span>
<span class="linenos">  46</span><span class="sd">    Inspired from minimally informative prior principles, it is popular in the plasma physics tomography community.</span>
<span class="linenos">  47</span><span class="sd">    The diffusivity decreases for increasing local intensity values, to preserve bright features.</span>
<span class="linenos">  48</span>
<span class="linenos">  49</span><span class="sd">    The MFI diffusion tensor is defined, for the :math:`i`-th pixel, as:</span>
<span class="linenos">  50</span>
<span class="linenos">  51</span><span class="sd">    .. math::</span>
<span class="linenos">  52</span><span class="sd">        \big(\mathbf{D}(\mathbf{f})\big)_i = (g(\mathbf{f}))_i \;\mathbf{I} = \begin{pmatrix}(g(\mathbf{f}))_i &amp; 0\\ 0 &amp; (g(\mathbf{f}))_i\end{pmatrix},</span>
<span class="linenos">  53</span>
<span class="linenos">  54</span><span class="sd">    where the diffusivity :math:`g` is defined in two possible ways:</span>
<span class="linenos">  55</span>
<span class="linenos">  56</span><span class="sd">    * in the *tame* case as</span>
<span class="linenos">  57</span>
<span class="linenos">  58</span><span class="sd">      .. math::</span>
<span class="linenos">  59</span><span class="sd">         (g(\mathbf{f}))_i = \frac{1}{1+\max\{\delta, f_i\}/\beta},\quad\delta\ll 1,</span>
<span class="linenos">  60</span><span class="sd">    :math:`\quad\;\;` where :math:`\beta` is a contrast parameter,</span>
<span class="linenos">  61</span>
<span class="linenos">  62</span><span class="sd">    * in the *untame* case as</span>
<span class="linenos">  63</span>
<span class="linenos">  64</span><span class="sd">      .. math::</span>
<span class="linenos">  65</span><span class="sd">         (g(\mathbf{f}))_i = \frac{1}{\max\{\delta, f_i\}},\quad\delta\ll 1,</span>
<span class="linenos">  66</span>
<span class="linenos">  67</span><span class="sd">    The gradient of the operator reads</span>
<span class="linenos">  68</span>
<span class="linenos">  69</span><span class="sd">    .. math::</span>
<span class="linenos">  70</span><span class="sd">       -\mathrm{div}(\mathbf{D}(\mathbf{f})\boldsymbol{\nabla}\mathbf{f})-\sum_{i=0}^{N_{tot}-1}\frac{\vert(\boldsymbol{\nabla}\mathbf{f})_i\vert^2}{(g(\mathbf{f}))_i^2}\;,</span>
<span class="linenos">  71</span>
<span class="linenos">  72</span><span class="sd">    where the sum is an optional balloon force `extra_term`, which can be included or not.</span>
<span class="linenos">  73</span>
<span class="linenos">  74</span><span class="sd">    We recommend using the *tame* version, since it is better behaved: the *untame* version requires very small</span>
<span class="linenos">  75</span><span class="sd">    steps to be stable. Furthermore, we recommend including the extra term, because in this case the</span>
<span class="linenos">  76</span><span class="sd">    potential :math:`\phi` can be defined.</span>
<span class="linenos">  77</span>
<span class="linenos">  78</span><span class="sd">    Parameters</span>
<span class="linenos">  79</span><span class="sd">    ----------</span>
<span class="linenos">  80</span><span class="sd">    dim_shape: NDArrayShape</span>
<span class="linenos">  81</span><span class="sd">        Shape of the input array.</span>
<span class="linenos">  82</span><span class="sd">    extra_term: bool</span>
<span class="linenos">  83</span><span class="sd">        Whether the extra term arising from the differentiation of the MFI functional should be</span>
<span class="linenos">  84</span><span class="sd">        included. Defaults to `True` (recommended). If set to `False` (*linearized MFI*), the MFI diffusion operator</span>
<span class="linenos">  85</span><span class="sd">        does not admit a potential and the ``apply()`` method is not defined.</span>
<span class="linenos">  86</span><span class="sd">    beta: Real</span>
<span class="linenos">  87</span><span class="sd">        Contrast parameter, determines the magnitude above which image gradients are preserved. Defaults to 1.</span>
<span class="linenos">  88</span><span class="sd">    clipping_value: Real</span>
<span class="linenos">  89</span><span class="sd">        Clipping value :math:`\delta` in the expression of the MFI diffusivity. Defaults to 1e-5.</span>
<span class="linenos">  90</span><span class="sd">    tame: bool</span>
<span class="linenos">  91</span><span class="sd">       Whether tame or untame version should be used. Defaults to `True` (tame, recommended).</span>
<span class="linenos">  92</span><span class="sd">    sampling: Real, list[Real]</span>
<span class="linenos">  93</span><span class="sd">            Sampling step (i.e. distance between two consecutive elements of an array).</span>
<span class="linenos">  94</span><span class="sd">            Defaults to 1.</span>
<span class="linenos">  95</span>
<span class="linenos">  96</span><span class="sd">    Returns</span>
<span class="linenos">  97</span><span class="sd">    -------</span>
<span class="linenos">  98</span><span class="sd">    op: OpT</span>
<span class="linenos">  99</span><span class="sd">            MFI diffusion operator.</span>
<span class="linenos"> 100</span>
<span class="linenos"> 101</span><span class="sd">    &quot;&quot;&quot;</span>
<span class="linenos"> 102</span>
<span class="linenos"> 103</span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<span class="linenos"> 104</span>        <span class="bp">self</span><span class="p">,</span>
<span class="linenos"> 105</span>        <span class="n">dim_shape</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">NDArrayShape</span><span class="p">,</span>
<span class="linenos"> 106</span>        <span class="n">extra_term</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="linenos"> 107</span>        <span class="n">beta</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">Real</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<span class="linenos"> 108</span>        <span class="n">clipping_value</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">Real</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="p">,</span>
<span class="linenos"> 109</span>        <span class="n">tame</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="linenos"> 110</span>        <span class="n">sampling</span><span class="p">:</span> <span class="n">typ</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">pyct</span><span class="o">.</span><span class="n">Real</span><span class="p">,</span> <span class="n">cabc</span><span class="o">.</span><span class="n">Sequence</span><span class="p">[</span><span class="n">pyct</span><span class="o">.</span><span class="n">Real</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<span class="linenos"> 111</span>    <span class="p">):</span>
<span class="linenos"> 112</span>        <span class="n">gradient</span> <span class="o">=</span> <span class="n">pydiff</span><span class="o">.</span><span class="n">Gradient</span><span class="p">(</span>
<span class="linenos"> 113</span>            <span class="n">dim_shape</span><span class="o">=</span><span class="n">dim_shape</span><span class="p">,</span>
<span class="linenos"> 114</span>            <span class="n">directions</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
<span class="linenos"> 115</span>            <span class="n">diff_method</span><span class="o">=</span><span class="s2">&quot;fd&quot;</span><span class="p">,</span>
<span class="linenos"> 116</span>            <span class="n">scheme</span><span class="o">=</span><span class="s2">&quot;forward&quot;</span><span class="p">,</span>
<span class="linenos"> 117</span>            <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;symmetric&quot;</span><span class="p">,</span>
<span class="linenos"> 118</span>            <span class="n">sampling</span><span class="o">=</span><span class="n">sampling</span><span class="p">,</span>
<span class="linenos"> 119</span>        <span class="p">)</span>
<span class="linenos"> 120</span>        <span class="n">mfi_diffusion_coeff</span> <span class="o">=</span> <span class="n">DiffusionCoeffIsotropic</span><span class="p">(</span>
<span class="linenos"> 121</span>            <span class="n">dim_shape</span><span class="o">=</span><span class="n">dim_shape</span><span class="p">,</span>
<span class="linenos"> 122</span>            <span class="n">diffusivity</span><span class="o">=</span><span class="n">MfiDiffusivity</span><span class="p">(</span><span class="n">dim_shape</span><span class="o">=</span><span class="n">dim_shape</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="n">beta</span><span class="p">,</span> <span class="n">clipping_value</span><span class="o">=</span><span class="n">clipping_value</span><span class="p">,</span> <span class="n">tame</span><span class="o">=</span><span class="n">tame</span><span class="p">),</span>
<span class="linenos"> 123</span>        <span class="p">)</span>
<span class="linenos"> 124</span>        <span class="k">if</span> <span class="n">extra_term</span><span class="p">:</span>
<span class="linenos"> 125</span>            <span class="n">mfi_extra_term</span> <span class="o">=</span> <span class="n">MfiExtraTerm</span><span class="p">(</span>
<span class="linenos"> 126</span>                <span class="n">dim_shape</span><span class="o">=</span><span class="n">dim_shape</span><span class="p">,</span> <span class="n">gradient</span><span class="o">=</span><span class="n">gradient</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="n">beta</span><span class="p">,</span> <span class="n">clipping_value</span><span class="o">=</span><span class="n">clipping_value</span><span class="p">,</span> <span class="n">tame</span><span class="o">=</span><span class="n">tame</span>
<span class="linenos"> 127</span>            <span class="p">)</span>
<span class="linenos"> 128</span>            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
<span class="linenos"> 129</span>                <span class="n">dim_shape</span><span class="p">,</span>
<span class="linenos"> 130</span>                <span class="n">gradient</span><span class="o">=</span><span class="n">gradient</span><span class="p">,</span>
<span class="linenos"> 131</span>                <span class="n">diffusion_coefficient</span><span class="o">=</span><span class="n">mfi_diffusion_coeff</span><span class="p">,</span>
<span class="linenos"> 132</span>                <span class="n">extra_diffusion_term</span><span class="o">=</span><span class="n">mfi_extra_term</span><span class="p">,</span>
<span class="linenos"> 133</span>            <span class="p">)</span>
<span class="linenos"> 134</span>        <span class="k">else</span><span class="p">:</span>
<span class="linenos"> 135</span>            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">dim_shape</span><span class="p">,</span> <span class="n">gradient</span><span class="o">=</span><span class="n">gradient</span><span class="p">,</span> <span class="n">diffusion_coefficient</span><span class="o">=</span><span class="n">mfi_diffusion_coeff</span><span class="p">)</span>
<span class="linenos"> 136</span>        <span class="c1"># initialize lipschitz constants. should this be done instead inside _DiffusionOp.__init__ ??</span>
<span class="linenos"> 137</span>        <span class="k">if</span> <span class="n">tame</span><span class="p">:</span>
<span class="linenos"> 138</span>            <span class="bp">self</span><span class="o">.</span><span class="n">diff_lipschitz</span> <span class="o">=</span> <span class="n">gradient</span><span class="o">.</span><span class="n">lipschitz</span><span class="o">**</span><span class="mi">2</span>
<span class="linenos"> 139</span>        <span class="k">else</span><span class="p">:</span>
<span class="linenos"> 140</span>            <span class="bp">self</span><span class="o">.</span><span class="n">diff_lipschitz</span> <span class="o">=</span> <span class="n">gradient</span><span class="o">.</span><span class="n">lipschitz</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="n">clipping_value</span>
<span class="linenos"> 141</span>        <span class="c1"># REMARK: I think that with extra term we don&#39;t have lipschitzianity, only Holder-continuity order 2.</span>
<span class="linenos"> 142</span>        <span class="c1"># However, I did not observe instability in practice. I think it&#39;s due to denominator or order norm(x)!</span>
<span class="linenos"> 143</span>        <span class="c1"># if that&#39;s true, a reasonable estimate would be the following (doubling diff_lipschitz)</span>
<span class="linenos"> 144</span>        <span class="k">if</span> <span class="n">extra_term</span><span class="p">:</span>
<span class="linenos"> 145</span>            <span class="bp">self</span><span class="o">.</span><span class="n">diff_lipschitz</span> <span class="o">*=</span> <span class="mi">2</span>
<span class="linenos"> 146</span>
<span class="linenos"> 147</span>    <span class="k">def</span><span class="w"> </span><span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arr</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">NDArray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pyct</span><span class="o">.</span><span class="n">Real</span><span class="p">:</span>
<span class="linenos"> 148</span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">extra_diffusion_term</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos"> 149</span>            <span class="n">xp</span> <span class="o">=</span> <span class="n">pycu</span><span class="o">.</span><span class="n">get_array_module</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>  <span class="c1"># (batch,nchannels,nx,ny)</span>
<span class="linenos"> 150</span>            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_divergence_term</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>  <span class="c1"># (batch,nchannels,nx,ny)</span>
<span class="linenos"> 151</span>            <span class="k">return</span> <span class="n">xp</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;...jkl,...jkl-&gt;...&quot;</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">arr</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>  <span class="c1"># (batch,)</span>
<span class="linenos"> 152</span>        <span class="k">else</span><span class="p">:</span>
<span class="linenos"> 153</span>            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
<span class="linenos"> 154</span>                <span class="s2">&quot;&#39;apply()&#39; method not defined for MfiDiffusionOp with no MfiExtraTerm: no underlying variational intepretation&quot;</span>
<span class="linenos"> 155</span>            <span class="p">)</span></div>

<span class="linenos"> 156</span>
<span class="linenos"> 157</span>
<div class="viewcode-block" id="PeronaMalikDiffusion">
<a class="viewcode-back" href="../../../../api/operator.html#pyxu_diffops.operator.PeronaMalikDiffusion">[docs]</a>
<span class="linenos"> 158</span><span class="k">class</span><span class="w"> </span><span class="nc">PeronaMalikDiffusion</span><span class="p">(</span><span class="n">_Diffusion</span><span class="p">):</span>
<span class="linenos"> 159</span><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="linenos"> 160</span><span class="sd">    Perona-Malik diffusion operator, featuring an inhomogeneous isotropic diffusion tensor with Perona-Malik diffusivity. It can be used for edge-preserving smoothing.</span>
<span class="linenos"> 161</span><span class="sd">    It reduces the diffusion intensity in locations characterised by large gradients, effectively achieving edge-preservation.</span>
<span class="linenos"> 162</span>
<span class="linenos"> 163</span><span class="sd">    The gradient of the operator reads :math:`\nabla\phi(\mathbf{f})=-\mathrm{div}(\mathbf{D}(\mathbf{f})\boldsymbol{\nabla}\mathbf{f})`,</span>
<span class="linenos"> 164</span><span class="sd">    where :math:`\phi` is the potential.</span>
<span class="linenos"> 165</span>
<span class="linenos"> 166</span><span class="sd">    The Perona-Malik diffusion tensor is defined, for the :math:`i`-th pixel, as:</span>
<span class="linenos"> 167</span>
<span class="linenos"> 168</span><span class="sd">    .. math::</span>
<span class="linenos"> 169</span>
<span class="linenos"> 170</span><span class="sd">        \big(\mathbf{D}(\mathbf{f})\big)_i = (g(\mathbf{f}))_i \;\mathbf{I} = \begin{pmatrix}(g(\mathbf{f}))_i &amp; 0\\ 0 &amp; (g(\mathbf{f}))_i\end{pmatrix},</span>
<span class="linenos"> 171</span>
<span class="linenos"> 172</span><span class="sd">    where the diffusivity with contrast parameter :math:`\beta` is defined as:</span>
<span class="linenos"> 173</span>
<span class="linenos"> 174</span><span class="sd">    * :math:`(g(\mathbf{f}))_i = \exp(-\vert (\nabla_\sigma \mathbf{f})_i \vert ^2 / \beta^2)` in the exponential case,</span>
<span class="linenos"> 175</span>
<span class="linenos"> 176</span><span class="sd">    * :math:`(g(\mathbf{f}))_i = 1/\big( 1+\vert (\nabla_\sigma \mathbf{f})_i \vert ^2 / \beta^2\big)` in the rational case.</span>
<span class="linenos"> 177</span>
<span class="linenos"> 178</span><span class="sd">    Gaussian derivatives with width :math:`\sigma` are used for the gradient as customary with the ill-posed Perona-Malik diffusion process.</span>
<span class="linenos"> 179</span>
<span class="linenos"> 180</span><span class="sd">    In both cases, the corresponding divergence-based diffusion term admits a potential</span>
<span class="linenos"> 181</span><span class="sd">    (see [Tschumperle]_ for the exponential case): the ``apply()`` method is well-defined.</span>
<span class="linenos"> 182</span>
<span class="linenos"> 183</span><span class="sd">    Parameters</span>
<span class="linenos"> 184</span><span class="sd">    ----------</span>
<span class="linenos"> 185</span><span class="sd">    dim_shape: NDArrayShape</span>
<span class="linenos"> 186</span><span class="sd">        Shape of the input array.</span>
<span class="linenos"> 187</span><span class="sd">    beta: Real</span>
<span class="linenos"> 188</span><span class="sd">        Contrast parameter, determines the magnitude above which image gradients are preserved. Defaults to 1.</span>
<span class="linenos"> 189</span><span class="sd">    pm_fct: str</span>
<span class="linenos"> 190</span><span class="sd">        Perona-Malik diffusivity function. Must be either &#39;exponential&#39; or &#39;rational&#39;.</span>
<span class="linenos"> 191</span><span class="sd">    sigma_gd: Real</span>
<span class="linenos"> 192</span><span class="sd">        Standard deviation for kernel of Gaussian derivatives used for gradient computation. Defaults to 1.</span>
<span class="linenos"> 193</span><span class="sd">    sampling: Real, list[Real]</span>
<span class="linenos"> 194</span><span class="sd">            Sampling step (i.e. distance between two consecutive elements of an array).</span>
<span class="linenos"> 195</span><span class="sd">            Defaults to 1.</span>
<span class="linenos"> 196</span>
<span class="linenos"> 197</span><span class="sd">    Returns</span>
<span class="linenos"> 198</span><span class="sd">    -------</span>
<span class="linenos"> 199</span><span class="sd">    op: OpT</span>
<span class="linenos"> 200</span><span class="sd">            Perona-Malik diffusion operator.</span>
<span class="linenos"> 201</span>
<span class="linenos"> 202</span><span class="sd">    Example</span>
<span class="linenos"> 203</span><span class="sd">    -------</span>
<span class="linenos"> 204</span>
<span class="linenos"> 205</span><span class="sd">    .. plot::</span>
<span class="linenos"> 206</span>
<span class="linenos"> 207</span><span class="sd">        import numpy as np</span>
<span class="linenos"> 208</span><span class="sd">        import matplotlib.pyplot as plt</span>
<span class="linenos"> 209</span><span class="sd">        import pyxu.opt.solver as pysol</span>
<span class="linenos"> 210</span><span class="sd">        import pyxu.abc.solver as pysolver</span>
<span class="linenos"> 211</span><span class="sd">        import pyxu.opt.stop as pystop</span>
<span class="linenos"> 212</span><span class="sd">        import pyxu_diffops.operator as pyxop</span>
<span class="linenos"> 213</span><span class="sd">        import skimage as skim</span>
<span class="linenos"> 214</span>
<span class="linenos"> 215</span><span class="sd">        # Import RGB image</span>
<span class="linenos"> 216</span><span class="sd">        image = skim.data.cat().astype(float)</span>
<span class="linenos"> 217</span><span class="sd">        print(image.shape)  # (300, 451, 3)</span>
<span class="linenos"> 218</span>
<span class="linenos"> 219</span><span class="sd">        # Move color-stacking axis to front (needed for pyxu stacking convention)</span>
<span class="linenos"> 220</span><span class="sd">        image = np.moveaxis(image, 2, 0)</span>
<span class="linenos"> 221</span><span class="sd">        print(image.shape)  # (3, 300, 451)</span>
<span class="linenos"> 222</span>
<span class="linenos"> 223</span><span class="sd">        # Instantiate diffusion operator</span>
<span class="linenos"> 224</span><span class="sd">        pm_diffop = pyxop.PeronaMalikDiffusion(dim_shape=(3, 300, 451), beta=5)</span>
<span class="linenos"> 225</span>
<span class="linenos"> 226</span><span class="sd">        # Define PGD solver, with stopping criterion and starting point x0</span>
<span class="linenos"> 227</span><span class="sd">        stop_crit = pystop.MaxIter(n=100)</span>
<span class="linenos"> 228</span>
<span class="linenos"> 229</span><span class="sd">        # Perform 50 gradient flow iterations starting from x0</span>
<span class="linenos"> 230</span><span class="sd">        PGD = pysol.PGD(f=pm_diffop, show_progress=False, verbosity=100)</span>
<span class="linenos"> 231</span><span class="sd">        PGD.fit(**dict(mode=pysolver.SolverMode.BLOCK, x0=image, stop_crit=stop_crit,</span>
<span class="linenos"> 232</span><span class="sd">                       tau=2 / pm_diffop.diff_lipschitz))</span>
<span class="linenos"> 233</span><span class="sd">        pm_smoothed_image = PGD.solution()</span>
<span class="linenos"> 234</span>
<span class="linenos"> 235</span><span class="sd">        # Reshape images for plotting</span>
<span class="linenos"> 236</span><span class="sd">        image = np.moveaxis(image, 0, 2)</span>
<span class="linenos"> 237</span><span class="sd">        pm_smoothed_image = np.moveaxis(pm_smoothed_image, 0, 2)</span>
<span class="linenos"> 238</span>
<span class="linenos"> 239</span><span class="sd">        # Plot</span>
<span class="linenos"> 240</span><span class="sd">        fig, ax = plt.subplots(1, 2, figsize=(10, 5))</span>
<span class="linenos"> 241</span><span class="sd">        ax[0].imshow(image.astype(int))</span>
<span class="linenos"> 242</span><span class="sd">        ax[0].set_title(&quot;Image&quot;, fontsize=15)</span>
<span class="linenos"> 243</span><span class="sd">        ax[0].axis(&#39;off&#39;)</span>
<span class="linenos"> 244</span><span class="sd">        ax[1].imshow(pm_smoothed_image.astype(int))</span>
<span class="linenos"> 245</span><span class="sd">        ax[1].set_title(&quot;100 iterations Perona Malik diffusion&quot;, fontsize=15)</span>
<span class="linenos"> 246</span><span class="sd">        ax[1].axis(&#39;off&#39;)</span>
<span class="linenos"> 247</span>
<span class="linenos"> 248</span><span class="sd">    &quot;&quot;&quot;</span>
<span class="linenos"> 249</span>
<span class="linenos"> 250</span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<span class="linenos"> 251</span>        <span class="bp">self</span><span class="p">,</span>
<span class="linenos"> 252</span>        <span class="n">dim_shape</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">NDArrayShape</span><span class="p">,</span>
<span class="linenos"> 253</span>        <span class="n">beta</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">Real</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<span class="linenos"> 254</span>        <span class="n">pm_fct</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;exponential&quot;</span><span class="p">,</span>
<span class="linenos"> 255</span>        <span class="n">sigma_gd</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">Real</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<span class="linenos"> 256</span>        <span class="n">sampling</span><span class="p">:</span> <span class="n">typ</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">pyct</span><span class="o">.</span><span class="n">Real</span><span class="p">,</span> <span class="n">cabc</span><span class="o">.</span><span class="n">Sequence</span><span class="p">[</span><span class="n">pyct</span><span class="o">.</span><span class="n">Real</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<span class="linenos"> 257</span>    <span class="p">):</span>
<span class="linenos"> 258</span>        <span class="n">gradient</span> <span class="o">=</span> <span class="n">pydiff</span><span class="o">.</span><span class="n">Gradient</span><span class="p">(</span>
<span class="linenos"> 259</span>            <span class="n">dim_shape</span><span class="o">=</span><span class="n">dim_shape</span><span class="p">,</span>
<span class="linenos"> 260</span>            <span class="n">directions</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
<span class="linenos"> 261</span>            <span class="n">diff_method</span><span class="o">=</span><span class="s2">&quot;fd&quot;</span><span class="p">,</span>
<span class="linenos"> 262</span>            <span class="n">scheme</span><span class="o">=</span><span class="s2">&quot;forward&quot;</span><span class="p">,</span>
<span class="linenos"> 263</span>            <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;symmetric&quot;</span><span class="p">,</span>
<span class="linenos"> 264</span>            <span class="n">sampling</span><span class="o">=</span><span class="n">sampling</span><span class="p">,</span>
<span class="linenos"> 265</span>        <span class="p">)</span>
<span class="linenos"> 266</span>        <span class="n">gaussian_gradient</span> <span class="o">=</span> <span class="n">pydiff</span><span class="o">.</span><span class="n">Gradient</span><span class="p">(</span>
<span class="linenos"> 267</span>            <span class="n">dim_shape</span><span class="o">=</span><span class="n">dim_shape</span><span class="p">,</span> <span class="n">directions</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">diff_method</span><span class="o">=</span><span class="s2">&quot;gd&quot;</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma_gd</span><span class="p">,</span> <span class="n">sampling</span><span class="o">=</span><span class="n">sampling</span>
<span class="linenos"> 268</span>        <span class="p">)</span>
<span class="linenos"> 269</span>        <span class="n">pm_diffusion_coeff</span> <span class="o">=</span> <span class="n">DiffusionCoeffIsotropic</span><span class="p">(</span>
<span class="linenos"> 270</span>            <span class="n">dim_shape</span><span class="o">=</span><span class="n">dim_shape</span><span class="p">,</span>
<span class="linenos"> 271</span>            <span class="n">diffusivity</span><span class="o">=</span><span class="n">PeronaMalikDiffusivity</span><span class="p">(</span>
<span class="linenos"> 272</span>                <span class="n">dim_shape</span><span class="o">=</span><span class="n">dim_shape</span><span class="p">,</span> <span class="n">gradient</span><span class="o">=</span><span class="n">gaussian_gradient</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="n">beta</span><span class="p">,</span> <span class="n">pm_fct</span><span class="o">=</span><span class="n">pm_fct</span>
<span class="linenos"> 273</span>            <span class="p">),</span>
<span class="linenos"> 274</span>        <span class="p">)</span>
<span class="linenos"> 275</span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">dim_shape</span><span class="p">,</span> <span class="n">gradient</span><span class="o">=</span><span class="n">gradient</span><span class="p">,</span> <span class="n">diffusion_coefficient</span><span class="o">=</span><span class="n">pm_diffusion_coeff</span><span class="p">)</span>
<span class="linenos"> 276</span>        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span>
<span class="linenos"> 277</span>        <span class="bp">self</span><span class="o">.</span><span class="n">pm_fct</span> <span class="o">=</span> <span class="n">pm_fct</span>
<span class="linenos"> 278</span>        <span class="c1"># initialize lipschitz constants. should this be done instead inside _DiffusionOp.__init__ ??</span>
<span class="linenos"> 279</span>        <span class="bp">self</span><span class="o">.</span><span class="n">diff_lipschitz</span> <span class="o">=</span> <span class="n">gradient</span><span class="o">.</span><span class="n">lipschitz</span><span class="o">**</span><span class="mi">2</span>
<span class="linenos"> 280</span>
<span class="linenos"> 281</span>    <span class="k">def</span><span class="w"> </span><span class="nf">_apply_exponential</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arr</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">NDArray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pyct</span><span class="o">.</span><span class="n">Real</span><span class="p">:</span>
<span class="linenos"> 282</span>        <span class="n">xp</span> <span class="o">=</span> <span class="n">pycu</span><span class="o">.</span><span class="n">get_array_module</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>  <span class="c1"># (batch,nchannels,nx,ny)</span>
<span class="linenos"> 283</span>        <span class="c1"># Inplace implementation of</span>
<span class="linenos"> 284</span>        <span class="c1">#     0.5*(beta**2)*sum(1 - xp.exp(-grad_norm_sq/beta**2))</span>
<span class="linenos"> 285</span>        <span class="n">y</span> <span class="o">=</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">diffusion_coefficient</span><span class="o">.</span><span class="n">diffusivity</span><span class="o">.</span><span class="n">_compute_grad_norm_sq</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gradient</span><span class="p">)</span>  <span class="c1"># (batch,nchannels,nx,ny)</span>
<span class="linenos"> 286</span>        <span class="n">y</span> <span class="o">/=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="o">**</span><span class="mi">2</span>
<span class="linenos"> 287</span>        <span class="n">y</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">xp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="linenos"> 288</span>        <span class="n">z</span> <span class="o">=</span> <span class="n">xp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>  <span class="c1"># (batch,)</span>
<span class="linenos"> 289</span>        <span class="n">z</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="o">**</span><span class="mi">2</span>
<span class="linenos"> 290</span>        <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">z</span>  <span class="c1"># (batch,)</span>
<span class="linenos"> 291</span>
<span class="linenos"> 292</span>    <span class="k">def</span><span class="w"> </span><span class="nf">_apply_rational</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arr</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">NDArray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pyct</span><span class="o">.</span><span class="n">NDArray</span><span class="p">:</span>
<span class="linenos"> 293</span>        <span class="n">xp</span> <span class="o">=</span> <span class="n">pycu</span><span class="o">.</span><span class="n">get_array_module</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>  <span class="c1"># (batch,nchannels,nx,ny)</span>
<span class="linenos"> 294</span>        <span class="c1"># Inplace implementation of</span>
<span class="linenos"> 295</span>        <span class="c1">#   0.5*(beta**2)*sum(xp.log(1+grad_norm_sq/beta**2)</span>
<span class="linenos"> 296</span>        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">diffusion_coefficient</span><span class="o">.</span><span class="n">diffusivity</span><span class="o">.</span><span class="n">_compute_grad_norm_sq</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gradient</span><span class="p">)</span>  <span class="c1"># (batch,nchannels,nx,ny)</span>
<span class="linenos"> 297</span>        <span class="n">y</span> <span class="o">/=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="o">**</span><span class="mi">2</span>
<span class="linenos"> 298</span>        <span class="n">y</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="linenos"> 299</span>        <span class="n">y</span> <span class="o">=</span> <span class="n">xp</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="linenos"> 300</span>        <span class="n">z</span> <span class="o">=</span> <span class="n">xp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>  <span class="c1"># (batch,)</span>
<span class="linenos"> 301</span>        <span class="n">z</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="o">**</span><span class="mi">2</span>
<span class="linenos"> 302</span>        <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">z</span>  <span class="c1"># (batch,)</span>
<span class="linenos"> 303</span>
<span class="linenos"> 304</span>    <span class="k">def</span><span class="w"> </span><span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arr</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">NDArray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pyct</span><span class="o">.</span><span class="n">NDArray</span><span class="p">:</span>
<span class="linenos"> 305</span>        <span class="n">f</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
<span class="linenos"> 306</span>            <span class="n">exponential</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_apply_exponential</span><span class="p">,</span>
<span class="linenos"> 307</span>            <span class="n">rational</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_apply_rational</span><span class="p">,</span>
<span class="linenos"> 308</span>        <span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pm_fct</span><span class="p">)</span>
<span class="linenos"> 309</span>        <span class="n">out</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
<span class="linenos"> 310</span>        <span class="k">return</span> <span class="n">out</span></div>

<span class="linenos"> 311</span>
<span class="linenos"> 312</span>
<div class="viewcode-block" id="TikhonovDiffusion">
<a class="viewcode-back" href="../../../../api/operator.html#pyxu_diffops.operator.TikhonovDiffusion">[docs]</a>
<span class="linenos"> 313</span><span class="k">class</span><span class="w"> </span><span class="nc">TikhonovDiffusion</span><span class="p">(</span><span class="n">_Diffusion</span><span class="p">):</span>
<span class="linenos"> 314</span><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="linenos"> 315</span><span class="sd">    Tikhonov diffusion operator, featuring a homogeneous isotropic diffusion tensor with constant diffusivity. It</span>
<span class="linenos"> 316</span><span class="sd">    achieves Gaussian smoothing, isotropically smoothing in all directions. The diffusion intensity is identical at all</span>
<span class="linenos"> 317</span><span class="sd">    locations. Smoothing with this diffusion operator blurs the original image.</span>
<span class="linenos"> 318</span>
<span class="linenos"> 319</span><span class="sd">    The gradient of the operator reads :math:`\nabla\phi(\mathbf{f})=-\mathrm{div}(\boldsymbol{\nabla}\mathbf{f})=-\boldsymbol{\Delta}\mathbf{f}`;</span>
<span class="linenos"> 320</span><span class="sd">    it derives from the potential :math:`\phi=\Vert\boldsymbol{\nabla}\mathbf{f}\Vert_2^2`.</span>
<span class="linenos"> 321</span>
<span class="linenos"> 322</span><span class="sd">    The Tikohnov diffusion tensor is defined, for the :math:`i`-th pixel, as:</span>
<span class="linenos"> 323</span>
<span class="linenos"> 324</span><span class="sd">    .. math::</span>
<span class="linenos"> 325</span>
<span class="linenos"> 326</span><span class="sd">        \big(\mathbf{D}(\mathbf{f})\big)_i = \mathbf{I} = \begin{pmatrix}1 &amp; 0\\ 0 &amp; 1\end{pmatrix}.</span>
<span class="linenos"> 327</span>
<span class="linenos"> 328</span><span class="sd">    Parameters</span>
<span class="linenos"> 329</span><span class="sd">    ----------</span>
<span class="linenos"> 330</span><span class="sd">    dim_shape: NDArrayShape</span>
<span class="linenos"> 331</span><span class="sd">        Shape of the input array.</span>
<span class="linenos"> 332</span><span class="sd">    sampling: Real, list[Real]</span>
<span class="linenos"> 333</span><span class="sd">            Sampling step (i.e. distance between two consecutive elements of an array).</span>
<span class="linenos"> 334</span><span class="sd">            Defaults to 1.</span>
<span class="linenos"> 335</span>
<span class="linenos"> 336</span><span class="sd">    Returns</span>
<span class="linenos"> 337</span><span class="sd">    -------</span>
<span class="linenos"> 338</span><span class="sd">    op: OpT</span>
<span class="linenos"> 339</span><span class="sd">            Tikhonov diffusion operator.</span>
<span class="linenos"> 340</span>
<span class="linenos"> 341</span><span class="sd">    Example</span>
<span class="linenos"> 342</span><span class="sd">    -------</span>
<span class="linenos"> 343</span>
<span class="linenos"> 344</span><span class="sd">    .. plot::</span>
<span class="linenos"> 345</span>
<span class="linenos"> 346</span><span class="sd">        import numpy as np</span>
<span class="linenos"> 347</span><span class="sd">        import matplotlib.pyplot as plt</span>
<span class="linenos"> 348</span><span class="sd">        import pyxu.opt.solver as pysol</span>
<span class="linenos"> 349</span><span class="sd">        import pyxu.abc.solver as pysolver</span>
<span class="linenos"> 350</span><span class="sd">        import pyxu.opt.stop as pystop</span>
<span class="linenos"> 351</span><span class="sd">        import pyxu_diffops.operator as pyxop</span>
<span class="linenos"> 352</span><span class="sd">        import skimage as skim</span>
<span class="linenos"> 353</span>
<span class="linenos"> 354</span><span class="sd">        # Import RGB image</span>
<span class="linenos"> 355</span><span class="sd">        image = skim.data.cat().astype(float)</span>
<span class="linenos"> 356</span><span class="sd">        print(image.shape)  # (300, 451, 3)</span>
<span class="linenos"> 357</span>
<span class="linenos"> 358</span><span class="sd">        # Move color-stacking axis to front (needed for pyxu stacking convention)</span>
<span class="linenos"> 359</span><span class="sd">        image = np.moveaxis(image, 2, 0)</span>
<span class="linenos"> 360</span><span class="sd">        print(image.shape)  # (3, 300, 451)</span>
<span class="linenos"> 361</span>
<span class="linenos"> 362</span><span class="sd">        # Instantiate diffusion operator</span>
<span class="linenos"> 363</span><span class="sd">        tikh_diffop = pyxop.TikhonovDiffusion(dim_shape=(3, 300, 451))</span>
<span class="linenos"> 364</span>
<span class="linenos"> 365</span><span class="sd">        # Define PGD solver, with stopping criterion and starting point x0</span>
<span class="linenos"> 366</span><span class="sd">        stop_crit = pystop.MaxIter(n=100)</span>
<span class="linenos"> 367</span>
<span class="linenos"> 368</span><span class="sd">        # Perform 50 gradient flow iterations starting from x0</span>
<span class="linenos"> 369</span><span class="sd">        PGD = pysol.PGD(f=tikh_diffop, show_progress=False, verbosity=100)</span>
<span class="linenos"> 370</span><span class="sd">        PGD.fit(**dict(mode=pysolver.SolverMode.BLOCK, x0=image, stop_crit=stop_crit,</span>
<span class="linenos"> 371</span><span class="sd">                       tau=2 / tikh_diffop.diff_lipschitz))</span>
<span class="linenos"> 372</span><span class="sd">        tikh_smoothed_image = PGD.solution()</span>
<span class="linenos"> 373</span>
<span class="linenos"> 374</span><span class="sd">        # Reshape images for plotting.</span>
<span class="linenos"> 375</span><span class="sd">        image = np.moveaxis(image, 0, 2)</span>
<span class="linenos"> 376</span><span class="sd">        tikh_smoothed_image = np.moveaxis(tikh_smoothed_image, 0, 2)</span>
<span class="linenos"> 377</span>
<span class="linenos"> 378</span><span class="sd">        # Plot</span>
<span class="linenos"> 379</span><span class="sd">        fig, ax = plt.subplots(1, 2, figsize=(10, 5))</span>
<span class="linenos"> 380</span><span class="sd">        ax[0].imshow(image.astype(int))</span>
<span class="linenos"> 381</span><span class="sd">        ax[0].set_title(&quot;Image&quot;, fontsize=15)</span>
<span class="linenos"> 382</span><span class="sd">        ax[0].axis(&#39;off&#39;)</span>
<span class="linenos"> 383</span><span class="sd">        ax[1].imshow(tikh_smoothed_image.astype(int))</span>
<span class="linenos"> 384</span><span class="sd">        ax[1].set_title(&quot;100 iterations Tikhonov smoothing&quot;, fontsize=15)</span>
<span class="linenos"> 385</span><span class="sd">        ax[1].axis(&#39;off&#39;)</span>
<span class="linenos"> 386</span>
<span class="linenos"> 387</span><span class="sd">    &quot;&quot;&quot;</span>
<span class="linenos"> 388</span>
<span class="linenos"> 389</span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<span class="linenos"> 390</span>        <span class="bp">self</span><span class="p">,</span>
<span class="linenos"> 391</span>        <span class="n">dim_shape</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">NDArrayShape</span><span class="p">,</span>
<span class="linenos"> 392</span>        <span class="n">sampling</span><span class="p">:</span> <span class="n">typ</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">pyct</span><span class="o">.</span><span class="n">Real</span><span class="p">,</span> <span class="n">cabc</span><span class="o">.</span><span class="n">Sequence</span><span class="p">[</span><span class="n">pyct</span><span class="o">.</span><span class="n">Real</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<span class="linenos"> 393</span>    <span class="p">):</span>
<span class="linenos"> 394</span>        <span class="n">gradient</span> <span class="o">=</span> <span class="n">pydiff</span><span class="o">.</span><span class="n">Gradient</span><span class="p">(</span>
<span class="linenos"> 395</span>            <span class="n">dim_shape</span><span class="o">=</span><span class="n">dim_shape</span><span class="p">,</span>
<span class="linenos"> 396</span>            <span class="n">directions</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
<span class="linenos"> 397</span>            <span class="n">diff_method</span><span class="o">=</span><span class="s2">&quot;fd&quot;</span><span class="p">,</span>
<span class="linenos"> 398</span>            <span class="n">scheme</span><span class="o">=</span><span class="s2">&quot;forward&quot;</span><span class="p">,</span>
<span class="linenos"> 399</span>            <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;symmetric&quot;</span><span class="p">,</span>
<span class="linenos"> 400</span>            <span class="n">sampling</span><span class="o">=</span><span class="n">sampling</span><span class="p">,</span>
<span class="linenos"> 401</span>        <span class="p">)</span>
<span class="linenos"> 402</span>        <span class="n">tikhonov_diffusion_coeff</span> <span class="o">=</span> <span class="n">DiffusionCoeffIsotropic</span><span class="p">(</span><span class="n">dim_shape</span><span class="o">=</span><span class="n">dim_shape</span><span class="p">)</span>
<span class="linenos"> 403</span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">dim_shape</span><span class="p">,</span> <span class="n">gradient</span><span class="o">=</span><span class="n">gradient</span><span class="p">,</span> <span class="n">diffusion_coefficient</span><span class="o">=</span><span class="n">tikhonov_diffusion_coeff</span><span class="p">)</span>
<span class="linenos"> 404</span>        <span class="c1"># initialize lipschitz constants. should this be done instead inside _DiffusionOp.__init__ ??</span>
<span class="linenos"> 405</span>        <span class="bp">self</span><span class="o">.</span><span class="n">diff_lipschitz</span> <span class="o">=</span> <span class="n">gradient</span><span class="o">.</span><span class="n">lipschitz</span><span class="o">**</span><span class="mi">2</span>
<span class="linenos"> 406</span>
<span class="linenos"> 407</span>    <span class="k">def</span><span class="w"> </span><span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arr</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">NDArray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pyct</span><span class="o">.</span><span class="n">Real</span><span class="p">:</span>
<span class="linenos"> 408</span>        <span class="n">xp</span> <span class="o">=</span> <span class="n">pycu</span><span class="o">.</span><span class="n">get_array_module</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>  <span class="c1"># (batch,nchannels,nx,ny)</span>
<span class="linenos"> 409</span>        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_divergence_term</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>  <span class="c1"># (batch,nchannels,nx,ny)</span>
<span class="linenos"> 410</span>        <span class="k">return</span> <span class="n">xp</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;...jkl,...jkl-&gt;...&quot;</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">arr</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>  <span class="c1"># (batch,)</span></div>

<span class="linenos"> 411</span>
<span class="linenos"> 412</span>
<div class="viewcode-block" id="TotalVariationDiffusion">
<a class="viewcode-back" href="../../../../api/operator.html#pyxu_diffops.operator.TotalVariationDiffusion">[docs]</a>
<span class="linenos"> 413</span><span class="k">class</span><span class="w"> </span><span class="nc">TotalVariationDiffusion</span><span class="p">(</span><span class="n">_Diffusion</span><span class="p">):</span>
<span class="linenos"> 414</span><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="linenos"> 415</span><span class="sd">    Total variation (TV) diffusion operator, featuring an inhomogeneous isotropic diffusion tensor. It can be used for edge-enhancing smoothing.</span>
<span class="linenos"> 416</span><span class="sd">    It reduces the diffusion intensity in locations characterised by large gradients, effectively achieving edge-preservation. The</span>
<span class="linenos"> 417</span><span class="sd">    diffusion operator formulation of total variation regularization stems from the Euler-Lagrange equations associated to the</span>
<span class="linenos"> 418</span><span class="sd">    problem of minimizing the TV regularization functional.</span>
<span class="linenos"> 419</span>
<span class="linenos"> 420</span><span class="sd">    The gradient of the operator reads :math:`\nabla\phi(\mathbf{f})=-\mathrm{div}(\mathbf{D}(\mathbf{f})\boldsymbol{\nabla}\mathbf{f})`,</span>
<span class="linenos"> 421</span><span class="sd">    deriving from the total variation potential :math:`\phi`.</span>
<span class="linenos"> 422</span><span class="sd">    In the TV classical (*untame*) formulation, it holds</span>
<span class="linenos"> 423</span><span class="sd">    :math:`\phi=\Vert \boldsymbol{\nabla}\mathbf{f}\Vert_{2,1}=\sum_{i=0}^{N_{tot}-1}\vert(\boldsymbol{\nabla}\mathbf{f})_i\vert`.</span>
<span class="linenos"> 424</span><span class="sd">    A similar definition holds for its *tame* version (recommended).</span>
<span class="linenos"> 425</span>
<span class="linenos"> 426</span><span class="sd">    The TV diffusion tensor is defined, for the :math:`i`-th pixel, as:</span>
<span class="linenos"> 427</span>
<span class="linenos"> 428</span><span class="sd">    .. math::</span>
<span class="linenos"> 429</span>
<span class="linenos"> 430</span><span class="sd">        \big(\mathbf{D}(\mathbf{f})\big)_i = (g(\mathbf{f}))_i \;\mathbf{I} = \begin{pmatrix}(g(\mathbf{f}))_i &amp; 0\\ 0 &amp; (g(\mathbf{f}))_i\end{pmatrix}.</span>
<span class="linenos"> 431</span>
<span class="linenos"> 432</span><span class="sd">    The diffusivity can be defined in two possible ways:</span>
<span class="linenos"> 433</span>
<span class="linenos"> 434</span><span class="sd">    * in the *tame* case as</span>
<span class="linenos"> 435</span><span class="sd">    .. math ::</span>
<span class="linenos"> 436</span><span class="sd">        (g(\mathbf{f}))_i = \frac{\beta} { \sqrt{\beta^2+ \vert (\boldsymbol{\nabla} \mathbf{f})_i \vert ^2}}, \quad \forall i</span>
<span class="linenos"> 437</span>
<span class="linenos"> 438</span><span class="sd">    * in the *untame* case as</span>
<span class="linenos"> 439</span><span class="sd">    .. math ::</span>
<span class="linenos"> 440</span><span class="sd">        (g(\mathbf{f}))_i = \frac{1} { \vert (\boldsymbol{\nabla} \mathbf{f})_i \vert}, \quad \forall i.</span>
<span class="linenos"> 441</span>
<span class="linenos"> 442</span><span class="sd">    The *tame* formulation amounts to an approximation of the TV functional very similar to the Huber loss approach. The</span>
<span class="linenos"> 443</span><span class="sd">    parameter :math:`\beta` controls the quality of the smooth approximation of the :math:`L^2` norm</span>
<span class="linenos"> 444</span><span class="sd">    :math:`\vert (\boldsymbol{\nabla} \mathbf{f})_i \vert` involved in the TV</span>
<span class="linenos"> 445</span><span class="sd">    approach. Lower values correspond to better approximations but typically lead to larger computational cost.</span>
<span class="linenos"> 446</span>
<span class="linenos"> 447</span><span class="sd">    We recommended using the *tame* version; the *untame* one is unstable.</span>
<span class="linenos"> 448</span>
<span class="linenos"> 449</span><span class="sd">    Parameters</span>
<span class="linenos"> 450</span><span class="sd">    ----------</span>
<span class="linenos"> 451</span><span class="sd">    dim_shape: NDArrayShape</span>
<span class="linenos"> 452</span><span class="sd">        Shape of the input array.</span>
<span class="linenos"> 453</span><span class="sd">    beta: Real</span>
<span class="linenos"> 454</span><span class="sd">        Contrast parameter, determines the magnitude above which image gradients are preserved. Defaults to 1.</span>
<span class="linenos"> 455</span><span class="sd">    tame: bool</span>
<span class="linenos"> 456</span><span class="sd">       Whether tame or untame version should be used. Defaults to `True` (tame, recommended).</span>
<span class="linenos"> 457</span><span class="sd">    sampling: Real, list[Real]</span>
<span class="linenos"> 458</span><span class="sd">            Sampling step (i.e. distance between two consecutive elements of an array).</span>
<span class="linenos"> 459</span><span class="sd">            Defaults to 1.</span>
<span class="linenos"> 460</span>
<span class="linenos"> 461</span><span class="sd">    Returns</span>
<span class="linenos"> 462</span><span class="sd">    -------</span>
<span class="linenos"> 463</span><span class="sd">    op: OpT</span>
<span class="linenos"> 464</span><span class="sd">            Total variation diffusion operator.</span>
<span class="linenos"> 465</span>
<span class="linenos"> 466</span><span class="sd">    Example</span>
<span class="linenos"> 467</span><span class="sd">    -------</span>
<span class="linenos"> 468</span>
<span class="linenos"> 469</span><span class="sd">    .. plot::</span>
<span class="linenos"> 470</span>
<span class="linenos"> 471</span><span class="sd">        import numpy as np</span>
<span class="linenos"> 472</span><span class="sd">        import matplotlib.pyplot as plt</span>
<span class="linenos"> 473</span><span class="sd">        import pyxu.opt.solver as pysol</span>
<span class="linenos"> 474</span><span class="sd">        import pyxu.abc.solver as pysolver</span>
<span class="linenos"> 475</span><span class="sd">        import pyxu.opt.stop as pystop</span>
<span class="linenos"> 476</span><span class="sd">        import pyxu_diffops.operator as pyxop</span>
<span class="linenos"> 477</span><span class="sd">        import skimage as skim</span>
<span class="linenos"> 478</span>
<span class="linenos"> 479</span><span class="sd">        # Import RGB image</span>
<span class="linenos"> 480</span><span class="sd">        image = skim.data.cat().astype(float)</span>
<span class="linenos"> 481</span><span class="sd">        print(image.shape)  # (300, 451, 3)</span>
<span class="linenos"> 482</span>
<span class="linenos"> 483</span><span class="sd">        # Move color-stacking axis to front (needed for pyxu stacking convention)</span>
<span class="linenos"> 484</span><span class="sd">        image = np.moveaxis(image, 2, 0)</span>
<span class="linenos"> 485</span><span class="sd">        print(image.shape)  # (3, 300, 451)</span>
<span class="linenos"> 486</span>
<span class="linenos"> 487</span><span class="sd">        # Instantiate diffusion operator</span>
<span class="linenos"> 488</span><span class="sd">        tv_diffop = pyxop.TotalVariationDiffusion(dim_shape=(3, 300, 451), beta=2)</span>
<span class="linenos"> 489</span>
<span class="linenos"> 490</span><span class="sd">        # Define PGD solver, with stopping criterion and starting point x0</span>
<span class="linenos"> 491</span><span class="sd">        stop_crit = pystop.MaxIter(n=100)</span>
<span class="linenos"> 492</span>
<span class="linenos"> 493</span><span class="sd">        # Perform 50 gradient flow iterations starting from x0</span>
<span class="linenos"> 494</span><span class="sd">        PGD = pysol.PGD(f=tv_diffop, show_progress=False, verbosity=100)</span>
<span class="linenos"> 495</span><span class="sd">        PGD.fit(**dict(mode=pysolver.SolverMode.BLOCK, x0=image, stop_crit=stop_crit,</span>
<span class="linenos"> 496</span><span class="sd">                       tau=2/tv_diffop.diff_lipschitz))</span>
<span class="linenos"> 497</span><span class="sd">        tv_smoothed_image = PGD.solution()</span>
<span class="linenos"> 498</span>
<span class="linenos"> 499</span><span class="sd">        # Reshape images for plotting.</span>
<span class="linenos"> 500</span><span class="sd">        image = np.moveaxis(image, 0, 2)</span>
<span class="linenos"> 501</span><span class="sd">        tv_smoothed_image = np.moveaxis(tv_smoothed_image, 0, 2)</span>
<span class="linenos"> 502</span>
<span class="linenos"> 503</span><span class="sd">        # Plot</span>
<span class="linenos"> 504</span><span class="sd">        fig, ax = plt.subplots(1, 2, figsize=(10, 5))</span>
<span class="linenos"> 505</span><span class="sd">        ax[0].imshow(image.astype(int))</span>
<span class="linenos"> 506</span><span class="sd">        ax[0].set_title(&quot;Image&quot;, fontsize=15)</span>
<span class="linenos"> 507</span><span class="sd">        ax[0].axis(&#39;off&#39;)</span>
<span class="linenos"> 508</span><span class="sd">        ax[1].imshow(tv_smoothed_image.astype(int))</span>
<span class="linenos"> 509</span><span class="sd">        ax[1].set_title(&quot;100 iterations Total Variation smoothing&quot;, fontsize=15)</span>
<span class="linenos"> 510</span><span class="sd">        ax[1].axis(&#39;off&#39;)</span>
<span class="linenos"> 511</span>
<span class="linenos"> 512</span><span class="sd">    &quot;&quot;&quot;</span>
<span class="linenos"> 513</span>
<span class="linenos"> 514</span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<span class="linenos"> 515</span>        <span class="bp">self</span><span class="p">,</span>
<span class="linenos"> 516</span>        <span class="n">dim_shape</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">NDArrayShape</span><span class="p">,</span>
<span class="linenos"> 517</span>        <span class="n">beta</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">Real</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<span class="linenos"> 518</span>        <span class="n">tame</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="linenos"> 519</span>        <span class="c1"># sigma_gd: pyct.Real = 1,</span>
<span class="linenos"> 520</span>        <span class="n">sampling</span><span class="p">:</span> <span class="n">typ</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">pyct</span><span class="o">.</span><span class="n">Real</span><span class="p">,</span> <span class="n">cabc</span><span class="o">.</span><span class="n">Sequence</span><span class="p">[</span><span class="n">pyct</span><span class="o">.</span><span class="n">Real</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<span class="linenos"> 521</span>    <span class="p">):</span>
<span class="linenos"> 522</span>        <span class="n">gradient</span> <span class="o">=</span> <span class="n">pydiff</span><span class="o">.</span><span class="n">Gradient</span><span class="p">(</span>
<span class="linenos"> 523</span>            <span class="n">dim_shape</span><span class="o">=</span><span class="n">dim_shape</span><span class="p">,</span>
<span class="linenos"> 524</span>            <span class="n">directions</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
<span class="linenos"> 525</span>            <span class="n">diff_method</span><span class="o">=</span><span class="s2">&quot;fd&quot;</span><span class="p">,</span>
<span class="linenos"> 526</span>            <span class="n">scheme</span><span class="o">=</span><span class="s2">&quot;forward&quot;</span><span class="p">,</span>
<span class="linenos"> 527</span>            <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;symmetric&quot;</span><span class="p">,</span>
<span class="linenos"> 528</span>            <span class="n">sampling</span><span class="o">=</span><span class="n">sampling</span><span class="p">,</span>
<span class="linenos"> 529</span>        <span class="p">)</span>
<span class="linenos"> 530</span>        <span class="n">tv_diffusion_coeff</span> <span class="o">=</span> <span class="n">DiffusionCoeffIsotropic</span><span class="p">(</span>
<span class="linenos"> 531</span>            <span class="n">dim_shape</span><span class="o">=</span><span class="n">dim_shape</span><span class="p">,</span>
<span class="linenos"> 532</span>            <span class="n">diffusivity</span><span class="o">=</span><span class="n">TotalVariationDiffusivity</span><span class="p">(</span><span class="n">dim_shape</span><span class="o">=</span><span class="n">dim_shape</span><span class="p">,</span> <span class="n">gradient</span><span class="o">=</span><span class="n">gradient</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="n">beta</span><span class="p">,</span> <span class="n">tame</span><span class="o">=</span><span class="n">tame</span><span class="p">),</span>
<span class="linenos"> 533</span>        <span class="p">)</span>
<span class="linenos"> 534</span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">dim_shape</span><span class="p">,</span> <span class="n">gradient</span><span class="o">=</span><span class="n">gradient</span><span class="p">,</span> <span class="n">diffusion_coefficient</span><span class="o">=</span><span class="n">tv_diffusion_coeff</span><span class="p">)</span>
<span class="linenos"> 535</span>        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span>
<span class="linenos"> 536</span>        <span class="bp">self</span><span class="o">.</span><span class="n">tame</span> <span class="o">=</span> <span class="n">tame</span>
<span class="linenos"> 537</span>        <span class="c1"># initialize lipschitz constants. should this be done instead inside _DiffusionOp.__init__ ??</span>
<span class="linenos"> 538</span>        <span class="bp">self</span><span class="o">.</span><span class="n">diff_lipschitz</span> <span class="o">=</span> <span class="n">gradient</span><span class="o">.</span><span class="n">lipschitz</span><span class="o">**</span><span class="mi">2</span>
<span class="linenos"> 539</span>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">tame</span><span class="p">:</span>
<span class="linenos"> 540</span>            <span class="bp">self</span><span class="o">.</span><span class="n">diff_lipschitz</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
<span class="linenos"> 541</span>
<span class="linenos"> 542</span>    <span class="c1"># @pycrt.enforce_precision(i=&quot;arr&quot;)</span>
<span class="linenos"> 543</span>    <span class="k">def</span><span class="w"> </span><span class="nf">_apply_tame</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arr</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">NDArray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pyct</span><span class="o">.</span><span class="n">NDArray</span><span class="p">:</span>
<span class="linenos"> 544</span>        <span class="c1"># Inplace implementation of</span>
<span class="linenos"> 545</span>        <span class="c1">#   beta**2*sum(xp.sqrt(1+grad_norm_sq/beta**2)</span>
<span class="linenos"> 546</span>        <span class="n">xp</span> <span class="o">=</span> <span class="n">pycu</span><span class="o">.</span><span class="n">get_array_module</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
<span class="linenos"> 547</span>        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">diffusion_coefficient</span><span class="o">.</span><span class="n">diffusivity</span><span class="o">.</span><span class="n">_compute_grad_norm_sq</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gradient</span><span class="p">)</span>  <span class="c1"># (batch,nchannels,nx,ny)</span>
<span class="linenos"> 548</span>        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>  <span class="c1"># (batch,nx,ny) all channels are the same, duplicated information</span>
<span class="linenos"> 549</span>        <span class="n">y</span> <span class="o">/=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="o">**</span><span class="mi">2</span>
<span class="linenos"> 550</span>        <span class="n">y</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="linenos"> 551</span>        <span class="n">y</span> <span class="o">=</span> <span class="n">xp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="linenos"> 552</span>        <span class="n">z</span> <span class="o">=</span> <span class="n">xp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>  <span class="c1"># (batch,)</span>
<span class="linenos"> 553</span>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">z</span>
<span class="linenos"> 554</span>
<span class="linenos"> 555</span>    <span class="c1"># @pycrt.enforce_precision(i=&quot;arr&quot;)</span>
<span class="linenos"> 556</span>    <span class="k">def</span><span class="w"> </span><span class="nf">_apply_untamed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arr</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">NDArray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pyct</span><span class="o">.</span><span class="n">NDArray</span><span class="p">:</span>
<span class="linenos"> 557</span>        <span class="n">xp</span> <span class="o">=</span> <span class="n">pycu</span><span class="o">.</span><span class="n">get_array_module</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
<span class="linenos"> 558</span>        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">diffusion_coefficient</span><span class="o">.</span><span class="n">diffusivity</span><span class="o">.</span><span class="n">_compute_grad_norm_sq</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gradient</span><span class="p">)</span>  <span class="c1"># (batch,nchannels,nx,ny)</span>
<span class="linenos"> 559</span>        <span class="n">y</span> <span class="o">=</span> <span class="n">xp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:])</span>  <span class="c1"># (batch,nx,ny)</span>
<span class="linenos"> 560</span>        <span class="k">return</span> <span class="n">xp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>  <span class="c1"># (batch,)</span>
<span class="linenos"> 561</span>
<span class="linenos"> 562</span>    <span class="c1"># @pycrt.enforce_precision(i=&quot;arr&quot;)</span>
<span class="linenos"> 563</span>    <span class="c1"># @pycu.vectorize(&quot;arr&quot;)</span>
<span class="linenos"> 564</span>    <span class="k">def</span><span class="w"> </span><span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arr</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">NDArray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pyct</span><span class="o">.</span><span class="n">NDArray</span><span class="p">:</span>
<span class="linenos"> 565</span>        <span class="n">f</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_tame</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tame</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_untamed</span>
<span class="linenos"> 566</span>        <span class="n">out</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
<span class="linenos"> 567</span>        <span class="k">return</span> <span class="n">out</span></div>

<span class="linenos"> 568</span>
<span class="linenos"> 569</span>
<div class="viewcode-block" id="CurvaturePreservingDiffusionOp">
<a class="viewcode-back" href="../../../../api/operator.html#pyxu_diffops.operator.CurvaturePreservingDiffusionOp">[docs]</a>
<span class="linenos"> 570</span><span class="k">class</span><span class="w"> </span><span class="nc">CurvaturePreservingDiffusionOp</span><span class="p">(</span><span class="n">_Diffusion</span><span class="p">):</span>
<span class="linenos"> 571</span><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="linenos"> 572</span><span class="sd">    Curvature preserving diffusion operator [Tschumperle]_. This trace-based operator promotes curvature</span>
<span class="linenos"> 573</span><span class="sd">    preservation along a given vector field :math:`\mathbf{w}`, defined by a :math:`2`-dimensional</span>
<span class="linenos"> 574</span><span class="sd">    vector :math:`\mathbf{w}_i\in\mathbb{R}^2` for each pixel :math:`i`.</span>
<span class="linenos"> 575</span>
<span class="linenos"> 576</span><span class="sd">    The gradient of the operator reads</span>
<span class="linenos"> 577</span>
<span class="linenos"> 578</span><span class="sd">    .. math::</span>
<span class="linenos"> 579</span><span class="sd">        \frac{\partial\mathbf{f}}{\partial t} = -\mathrm{trace}\big(\mathbf{T}(\mathbf{w})\mathbf{H}(\mathbf{f})\big) - (\nabla\mathbf{f})^T \mathbf{J}_{\mathbf{w}}\mathbf{w},</span>
<span class="linenos"> 580</span>
<span class="linenos"> 581</span><span class="sd">    where the trace diffusion tensor :math:`\mathbf{T}(\mathbf{f})` is defined, for the :math:`i`-th pixel, as</span>
<span class="linenos"> 582</span>
<span class="linenos"> 583</span><span class="sd">    .. math::</span>
<span class="linenos"> 584</span><span class="sd">        \big(\mathbf{T}(\mathbf{f})\big)_i=\mathbf{w}_i\mathbf{w}_i^T.</span>
<span class="linenos"> 585</span>
<span class="linenos"> 586</span><span class="sd">    The curvature preserving diffusion operator does not admit a potential.</span>
<span class="linenos"> 587</span>
<span class="linenos"> 588</span><span class="sd">    Parameters</span>
<span class="linenos"> 589</span><span class="sd">    ----------</span>
<span class="linenos"> 590</span><span class="sd">    dim_shape: NDArrayShape</span>
<span class="linenos"> 591</span><span class="sd">        Shape of the input array.</span>
<span class="linenos"> 592</span><span class="sd">    curvature_preservation_field: NDArray</span>
<span class="linenos"> 593</span><span class="sd">        Vector field of shape :math:`(2, N_0, N_1)` along which curvature should be preserved.</span>
<span class="linenos"> 594</span><span class="sd">    sampling: Real, list[Real]</span>
<span class="linenos"> 595</span><span class="sd">            Sampling step (i.e. distance between two consecutive elements of an array).</span>
<span class="linenos"> 596</span><span class="sd">            Defaults to 1.</span>
<span class="linenos"> 597</span>
<span class="linenos"> 598</span><span class="sd">    Returns</span>
<span class="linenos"> 599</span><span class="sd">    -------</span>
<span class="linenos"> 600</span><span class="sd">    op: OpT</span>
<span class="linenos"> 601</span><span class="sd">            Curvature preserving diffusion operator.</span>
<span class="linenos"> 602</span>
<span class="linenos"> 603</span><span class="sd">    Example</span>
<span class="linenos"> 604</span><span class="sd">    -------</span>
<span class="linenos"> 605</span>
<span class="linenos"> 606</span><span class="sd">    .. plot::</span>
<span class="linenos"> 607</span>
<span class="linenos"> 608</span><span class="sd">        import numpy as np</span>
<span class="linenos"> 609</span><span class="sd">        import matplotlib.pyplot as plt</span>
<span class="linenos"> 610</span><span class="sd">        import pyxu.operator.linop.diff as pydiff</span>
<span class="linenos"> 611</span><span class="sd">        import pyxu.opt.solver as pysol</span>
<span class="linenos"> 612</span><span class="sd">        import pyxu.abc.solver as pysolver</span>
<span class="linenos"> 613</span><span class="sd">        import pyxu.opt.stop as pystop</span>
<span class="linenos"> 614</span><span class="sd">        import pyxu_diffops.operator as pyxop</span>
<span class="linenos"> 615</span><span class="sd">        import skimage as skim</span>
<span class="linenos"> 616</span>
<span class="linenos"> 617</span><span class="sd">        # Define random image</span>
<span class="linenos"> 618</span><span class="sd">        image = 255 * np.random.rand(3, 300, 451)</span>
<span class="linenos"> 619</span>
<span class="linenos"> 620</span><span class="sd">        # Define vector field, diffusion process will preserve curvature along it</span>
<span class="linenos"> 621</span><span class="sd">        image_center = np.array(image.shape[1:]) / 2 + [0.25, 0.25]</span>
<span class="linenos"> 622</span><span class="sd">        curvature_preservation_field = np.zeros((2, np.prod(image.shape[1:])))</span>
<span class="linenos"> 623</span><span class="sd">        curv_pres_1 = np.zeros(image.shape[1:])</span>
<span class="linenos"> 624</span><span class="sd">        curv_pres_2 = np.zeros(image.shape[1:])</span>
<span class="linenos"> 625</span><span class="sd">        for i in range(image.shape[1]):</span>
<span class="linenos"> 626</span><span class="sd">            for j in range(image.shape[2]):</span>
<span class="linenos"> 627</span><span class="sd">                theta = np.arctan2(-i + image_center[0], j - image_center[1])</span>
<span class="linenos"> 628</span><span class="sd">                curv_pres_1[i, j] = np.cos(theta)</span>
<span class="linenos"> 629</span><span class="sd">                curv_pres_2[i, j] = np.sin(theta)</span>
<span class="linenos"> 630</span><span class="sd">        curvature_preservation_field[0, :] = curv_pres_1.reshape(1, -1)</span>
<span class="linenos"> 631</span><span class="sd">        curvature_preservation_field[1, :] = curv_pres_2.reshape(1, -1)</span>
<span class="linenos"> 632</span><span class="sd">        curvature_preservation_field = curvature_preservation_field.reshape(2, *image.shape[1:])</span>
<span class="linenos"> 633</span>
<span class="linenos"> 634</span><span class="sd">        # Define curvature-preserving diffusion operator</span>
<span class="linenos"> 635</span><span class="sd">        CurvPresDiffusionOp = pyxop.CurvaturePreservingDiffusionOp(dim_shape=(3, 300, 451),</span>
<span class="linenos"> 636</span><span class="sd">                                                                    curvature_preservation_field=curvature_preservation_field)</span>
<span class="linenos"> 637</span>
<span class="linenos"> 638</span><span class="sd">        # Perform 500 gradient flow iterations</span>
<span class="linenos"> 639</span><span class="sd">        stop_crit = pystop.MaxIter(n=200)</span>
<span class="linenos"> 640</span><span class="sd">        PGD_curve = pysol.PGD(f=CurvPresDiffusionOp, g=None, show_progress=False, verbosity=100)</span>
<span class="linenos"> 641</span>
<span class="linenos"> 642</span><span class="sd">        PGD_curve.fit(**dict(mode=pysolver.SolverMode.BLOCK, x0=image, stop_crit=stop_crit, acceleration=False,</span>
<span class="linenos"> 643</span><span class="sd">                             tau=1 / CurvPresDiffusionOp.diff_lipschitz))</span>
<span class="linenos"> 644</span><span class="sd">        curv_smooth_image = PGD_curve.solution()</span>
<span class="linenos"> 645</span>
<span class="linenos"> 646</span><span class="sd">        # Reshape images for plotting.</span>
<span class="linenos"> 647</span><span class="sd">        image = np.moveaxis(image, 0, 2)</span>
<span class="linenos"> 648</span><span class="sd">        curv_smooth_image = np.moveaxis(curv_smooth_image, 0, 2)</span>
<span class="linenos"> 649</span><span class="sd">        # Rescale for better constrast</span>
<span class="linenos"> 650</span><span class="sd">        curv_smooth_image -= np.min(curv_smooth_image)</span>
<span class="linenos"> 651</span><span class="sd">        curv_smooth_image /= np.max(curv_smooth_image)</span>
<span class="linenos"> 652</span><span class="sd">        curv_smooth_image *= 255</span>
<span class="linenos"> 653</span>
<span class="linenos"> 654</span><span class="sd">        # Plot</span>
<span class="linenos"> 655</span><span class="sd">        fig, ax = plt.subplots(1, 3, figsize=(30, 6))</span>
<span class="linenos"> 656</span><span class="sd">        ax[0].imshow(image.astype(int), cmap=&quot;gray&quot;, aspect=&quot;auto&quot;)</span>
<span class="linenos"> 657</span><span class="sd">        ax[0].set_title(&quot;Image&quot;, fontsize=30)</span>
<span class="linenos"> 658</span><span class="sd">        ax[0].axis(&#39;off&#39;)</span>
<span class="linenos"> 659</span><span class="sd">        ax[1].quiver(curv_pres_2[::40, ::60], curv_pres_1[::40, ::60])</span>
<span class="linenos"> 660</span><span class="sd">        ax[1].set_title(&quot;Vector field&quot;, fontsize=30)</span>
<span class="linenos"> 661</span><span class="sd">        ax[1].axis(&#39;off&#39;)</span>
<span class="linenos"> 662</span><span class="sd">        ax[2].imshow(curv_smooth_image.astype(int), cmap=&quot;gray&quot;, aspect=&quot;auto&quot;)</span>
<span class="linenos"> 663</span><span class="sd">        ax[2].set_title(&quot;200 iterations Curvature Preserving&quot;, fontsize=30)</span>
<span class="linenos"> 664</span><span class="sd">        ax[2].axis(&#39;off&#39;)</span>
<span class="linenos"> 665</span>
<span class="linenos"> 666</span><span class="sd">    &quot;&quot;&quot;</span>
<span class="linenos"> 667</span>
<span class="linenos"> 668</span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<span class="linenos"> 669</span>        <span class="bp">self</span><span class="p">,</span>
<span class="linenos"> 670</span>        <span class="n">dim_shape</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">NDArrayShape</span><span class="p">,</span>
<span class="linenos"> 671</span>        <span class="n">curvature_preservation_field</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">NDArray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># (2dim,nx,ny)</span>
<span class="linenos"> 672</span>        <span class="n">sampling</span><span class="p">:</span> <span class="n">typ</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">pyct</span><span class="o">.</span><span class="n">Real</span><span class="p">,</span> <span class="n">cabc</span><span class="o">.</span><span class="n">Sequence</span><span class="p">[</span><span class="n">pyct</span><span class="o">.</span><span class="n">Real</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<span class="linenos"> 673</span>    <span class="p">):</span>
<span class="linenos"> 674</span>        <span class="n">xp</span> <span class="o">=</span> <span class="n">pycu</span><span class="o">.</span><span class="n">get_array_module</span><span class="p">(</span><span class="n">curvature_preservation_field</span><span class="p">)</span>
<span class="linenos"> 675</span>        <span class="bp">self</span><span class="o">.</span><span class="n">nchannels</span> <span class="o">=</span> <span class="n">dim_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="linenos"> 676</span>        <span class="n">gradient</span> <span class="o">=</span> <span class="n">pydiff</span><span class="o">.</span><span class="n">Gradient</span><span class="p">(</span>
<span class="linenos"> 677</span>            <span class="n">dim_shape</span><span class="o">=</span><span class="n">dim_shape</span><span class="p">,</span> <span class="n">directions</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">diff_method</span><span class="o">=</span><span class="s2">&quot;fd&quot;</span><span class="p">,</span> <span class="n">scheme</span><span class="o">=</span><span class="s2">&quot;central&quot;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;edge&quot;</span><span class="p">,</span> <span class="n">sampling</span><span class="o">=</span><span class="n">sampling</span>
<span class="linenos"> 678</span>        <span class="p">)</span>
<span class="linenos"> 679</span>        <span class="n">hessian</span> <span class="o">=</span> <span class="n">pydiff</span><span class="o">.</span><span class="n">Hessian</span><span class="p">(</span>
<span class="linenos"> 680</span>            <span class="n">dim_shape</span><span class="o">=</span><span class="n">dim_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">diff_method</span><span class="o">=</span><span class="s2">&quot;fd&quot;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;symmetric&quot;</span><span class="p">,</span> <span class="n">sampling</span><span class="o">=</span><span class="n">sampling</span><span class="p">,</span> <span class="n">scheme</span><span class="o">=</span><span class="s2">&quot;central&quot;</span><span class="p">,</span> <span class="n">accuracy</span><span class="o">=</span><span class="mi">2</span>
<span class="linenos"> 681</span>        <span class="p">)</span>
<span class="linenos"> 682</span>        <span class="n">curvature_preserving_term</span> <span class="o">=</span> <span class="n">CurvaturePreservingTerm</span><span class="p">(</span>
<span class="linenos"> 683</span>            <span class="n">dim_shape</span><span class="o">=</span><span class="n">dim_shape</span><span class="p">,</span> <span class="n">gradient</span><span class="o">=</span><span class="n">gradient</span><span class="p">,</span> <span class="n">curvature_preservation_field</span><span class="o">=</span><span class="n">curvature_preservation_field</span>
<span class="linenos"> 684</span>        <span class="p">)</span>
<span class="linenos"> 685</span>        <span class="c1"># assemble trace diffusion tensor</span>
<span class="linenos"> 686</span>        <span class="n">cf_sh</span> <span class="o">=</span> <span class="n">curvature_preservation_field</span><span class="o">.</span><span class="n">shape</span>
<span class="linenos"> 687</span>        <span class="n">tensors</span> <span class="o">=</span> <span class="n">curvature_preservation_field</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">cf_sh</span><span class="p">)</span> <span class="o">*</span> <span class="n">curvature_preservation_field</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
<span class="linenos"> 688</span>            <span class="n">cf_sh</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">cf_sh</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
<span class="linenos"> 689</span>        <span class="p">)</span>  <span class="c1"># (2dim,2dim,nx,ny)</span>
<span class="linenos"> 690</span>        <span class="n">tensors</span> <span class="o">=</span> <span class="n">xp</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">tensors</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">nchannels</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">)</span>  <span class="c1"># (2dim,2dim,nchannels,nx,ny)</span>
<span class="linenos"> 691</span>        <span class="n">trace_diffusion_coefficient</span> <span class="o">=</span> <span class="n">_DiffusionCoefficient</span><span class="p">(</span><span class="n">dim_shape</span><span class="o">=</span><span class="n">dim_shape</span><span class="p">,</span> <span class="n">isotropic</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">trace_term</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="linenos"> 692</span>        <span class="n">trace_diffusion_coefficient</span><span class="o">.</span><span class="n">set_frozen_coeff</span><span class="p">(</span><span class="n">tensors</span><span class="p">)</span>  <span class="c1"># (2dim,2dim,nchannels,nx,ny)</span>
<span class="linenos"> 693</span>
<span class="linenos"> 694</span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
<span class="linenos"> 695</span>            <span class="n">dim_shape</span><span class="p">,</span>
<span class="linenos"> 696</span>            <span class="n">hessian</span><span class="o">=</span><span class="n">hessian</span><span class="p">,</span>
<span class="linenos"> 697</span>            <span class="n">trace_diffusion_coefficient</span><span class="o">=</span><span class="n">trace_diffusion_coefficient</span><span class="p">,</span>
<span class="linenos"> 698</span>            <span class="n">extra_diffusion_term</span><span class="o">=</span><span class="n">curvature_preserving_term</span><span class="p">,</span>
<span class="linenos"> 699</span>        <span class="p">)</span>
<span class="linenos"> 700</span>        <span class="c1"># initialize lipschitz constants. should this be done instead inside _DiffusionOp.__init__ ? I think it&#39;s fine here.</span>
<span class="linenos"> 701</span>        <span class="bp">self</span><span class="o">.</span><span class="n">diff_lipschitz</span> <span class="o">=</span> <span class="p">(</span>
<span class="linenos"> 702</span>            <span class="n">hessian</span><span class="o">.</span><span class="n">lipschitz</span> <span class="o">*</span> <span class="n">curvature_preserving_term</span><span class="o">.</span><span class="n">max_norm</span> <span class="o">+</span> <span class="n">curvature_preserving_term</span><span class="o">.</span><span class="n">lipschitz</span>
<span class="linenos"> 703</span>        <span class="p">)</span></div>

<span class="linenos"> 704</span>
<span class="linenos"> 705</span>
<div class="viewcode-block" id="AnisEdgeEnhancingDiffusionOp">
<a class="viewcode-back" href="../../../../api/operator.html#pyxu_diffops.operator.AnisEdgeEnhancingDiffusionOp">[docs]</a>
<span class="linenos"> 706</span><span class="k">class</span><span class="w"> </span><span class="nc">AnisEdgeEnhancingDiffusionOp</span><span class="p">(</span><span class="n">_Diffusion</span><span class="p">):</span>
<span class="linenos"> 707</span><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="linenos"> 708</span><span class="sd">    Anisotropic edge-enhancing diffusion operator, featuring an inhomogeneous anisotropic diffusion tensor</span>
<span class="linenos"> 709</span><span class="sd">    defined as in [Weickert]_. The diffusion tensor is defined as a function of the</span>
<span class="linenos"> 710</span><span class="sd">    :py:class:`~pyxu.operator.linop.filter.StructureTensor`,</span>
<span class="linenos"> 711</span><span class="sd">    which is a tensor describing the properties of the image in the neighbourhood of each pixel.</span>
<span class="linenos"> 712</span><span class="sd">    This diffusion operator allows edge enhancement by reducing the flux in the direction of the</span>
<span class="linenos"> 713</span><span class="sd">    eigenvector of the structure tensor with largest eigenvalue. Essentially, smoothing across</span>
<span class="linenos"> 714</span><span class="sd">    the detected edges is inhibited in a more sophisticated way compared to isotropic approaches,</span>
<span class="linenos"> 715</span><span class="sd">    by considering not only the local gradient but its behaviour in a neighbourhood of the pixel.</span>
<span class="linenos"> 716</span>
<span class="linenos"> 717</span><span class="sd">    The gradient of the operator reads :math:`-\mathrm{div}(\mathbf{D}(\mathbf{f})\boldsymbol{\nabla}\mathbf{f})`.</span>
<span class="linenos"> 718</span>
<span class="linenos"> 719</span><span class="sd">    Let :math:`\mathbf{v}_0^i,\mathbf{v}_1^i` be the eigenvectors of the :math:`i`-th pixel structure tensor</span>
<span class="linenos"> 720</span><span class="sd">    :math:`S_i`, with eigenvalues :math:`e_0^i, e_1^i` sorted in decreasing order. The diffusion tensor is defined,</span>
<span class="linenos"> 721</span><span class="sd">    for the :math:`i`-th pixel, as the symmetric positive definite tensor:</span>
<span class="linenos"> 722</span>
<span class="linenos"> 723</span><span class="sd">    .. math::</span>
<span class="linenos"> 724</span><span class="sd">        \big(\mathbf{D}(\mathbf{f})\big)_i = \lambda_0^i\mathbf{v}_0^i(\mathbf{v}_0^i)^T+\lambda_1^i\mathbf{v}_1^i(\mathbf{v}_1^i)^T,</span>
<span class="linenos"> 725</span>
<span class="linenos"> 726</span>
<span class="linenos"> 727</span><span class="sd">    where the smoothing intensities along the two eigendirections are defined, to achieve edge-enhancing, as</span>
<span class="linenos"> 728</span>
<span class="linenos"> 729</span><span class="sd">    .. math::</span>
<span class="linenos"> 730</span><span class="sd">        \lambda_0^i &amp;= g(e_0^i) :=</span>
<span class="linenos"> 731</span><span class="sd">       \begin{cases}</span>
<span class="linenos"> 732</span><span class="sd">           1 &amp; \text{if } e_0^i = 0 \\</span>
<span class="linenos"> 733</span><span class="sd">           1 - \exp\big(\frac{-C}{(e_0^i/\beta)^m}\big) &amp; \text{if } e_0^i &gt;0,</span>
<span class="linenos"> 734</span><span class="sd">       \end{cases}\\</span>
<span class="linenos"> 735</span><span class="sd">        \lambda_1^i &amp;= 1,</span>
<span class="linenos"> 736</span>
<span class="linenos"> 737</span><span class="sd">    where :math:`\beta` is a contrast parameter, :math:`m` controls the decay rate of :math:`\lambda_0^i` as a function</span>
<span class="linenos"> 738</span><span class="sd">    of :math:`e_0^i`, and :math:`C\in\mathbb{R}` is a normalization constant (see [Weickert]_).</span>
<span class="linenos"> 739</span>
<span class="linenos"> 740</span><span class="sd">    Since :math:`\lambda_1^i \geq \lambda_0^i`, the smoothing intensity is stronger in the direction of the second</span>
<span class="linenos"> 741</span><span class="sd">    eigenvector of :math:`\mathbf{S}_i`, and therefore perpendicular to the (locally averaged) gradient.</span>
<span class="linenos"> 742</span><span class="sd">    Moreover, :math:`\lambda_0^i` is a decreasing function of :math:`e_0^i`, which indicates that when the gradient</span>
<span class="linenos"> 743</span><span class="sd">    magnitude is high (sharp edges), smoothing in the direction of the gradient is inhibited, i.e., edges are preserved.</span>
<span class="linenos"> 744</span>
<span class="linenos"> 745</span><span class="sd">    In general, the diffusion operator does not admit a potential. However, if the diffusion tensor is evaluated</span>
<span class="linenos"> 746</span><span class="sd">    at some image :math:`\tilde{\mathbf{f}}` and kept fixed to :math:`\mathbf{D}(\tilde{\mathbf{f}})`, the operator</span>
<span class="linenos"> 747</span><span class="sd">    derives from the potential :math:`\Vert\sqrt{\mathbf{D}(\tilde{\mathbf{f}})}\boldsymbol{\nabla}\mathbf{f}\Vert_2^2`.</span>
<span class="linenos"> 748</span><span class="sd">    By doing so, the smoothing directions and intensities are fixed according to the features of an image of interest.</span>
<span class="linenos"> 749</span><span class="sd">    This can be achieved passing a *freezing array* at initialization. In such cases, a *matrix-based implementation*</span>
<span class="linenos"> 750</span><span class="sd">    is recommended for efficiency.</span>
<span class="linenos"> 751</span>
<span class="linenos"> 752</span><span class="sd">    Parameters</span>
<span class="linenos"> 753</span><span class="sd">    ----------</span>
<span class="linenos"> 754</span><span class="sd">    dim_shape: NDArrayShape</span>
<span class="linenos"> 755</span><span class="sd">        Shape of the input array.</span>
<span class="linenos"> 756</span><span class="sd">    beta: Real</span>
<span class="linenos"> 757</span><span class="sd">        Contrast parameter, determines the gradient magnitude for edge enhancement. Defaults to 1.</span>
<span class="linenos"> 758</span><span class="sd">    m: Real</span>
<span class="linenos"> 759</span><span class="sd">        Decay parameter, determines how quickly the smoothing effect changes as a function of :math:`e_0^i/\beta`. Defaults to 4.</span>
<span class="linenos"> 760</span><span class="sd">    sigma_gd_st: Real</span>
<span class="linenos"> 761</span><span class="sd">       Gaussian width of the gaussian derivative involved in the structure tensor computation. Defaults to 2.</span>
<span class="linenos"> 762</span><span class="sd">    smooth_sigma_st: Real</span>
<span class="linenos"> 763</span><span class="sd">       Width of the Gaussian filter smoothing the structure tensor (local averaging). Defaults to 0 (recommended).</span>
<span class="linenos"> 764</span><span class="sd">    sampling: Real, list[Real]</span>
<span class="linenos"> 765</span><span class="sd">            Sampling step (i.e. distance between two consecutive elements of an array).</span>
<span class="linenos"> 766</span><span class="sd">            Defaults to 1.</span>
<span class="linenos"> 767</span><span class="sd">    freezing_arr: NDArray</span>
<span class="linenos"> 768</span><span class="sd">                Array at which the diffusion tensor is evaluated and then frozen.</span>
<span class="linenos"> 769</span><span class="sd">    matrix_based_impl: bool</span>
<span class="linenos"> 770</span><span class="sd">                Whether to use matrix based implementation or not. Defaults to False. Recommended to set `True` if</span>
<span class="linenos"> 771</span><span class="sd">                a ``freezing_arr`` is passed.</span>
<span class="linenos"> 772</span>
<span class="linenos"> 773</span><span class="sd">    Returns</span>
<span class="linenos"> 774</span><span class="sd">    -------</span>
<span class="linenos"> 775</span><span class="sd">    op: OpT</span>
<span class="linenos"> 776</span><span class="sd">            Anisotropic edge-enhancing diffusion operator.</span>
<span class="linenos"> 777</span>
<span class="linenos"> 778</span><span class="sd">    Example</span>
<span class="linenos"> 779</span><span class="sd">    -------</span>
<span class="linenos"> 780</span>
<span class="linenos"> 781</span><span class="sd">    .. plot::</span>
<span class="linenos"> 782</span>
<span class="linenos"> 783</span><span class="sd">        import numpy as np</span>
<span class="linenos"> 784</span><span class="sd">        import matplotlib.pyplot as plt</span>
<span class="linenos"> 785</span><span class="sd">        import pyxu.opt.solver as pysol</span>
<span class="linenos"> 786</span><span class="sd">        import pyxu.abc.solver as pysolver</span>
<span class="linenos"> 787</span><span class="sd">        import pyxu.opt.stop as pystop</span>
<span class="linenos"> 788</span><span class="sd">        import pyxu_diffops.operator as pyxop</span>
<span class="linenos"> 789</span><span class="sd">        import skimage as skim</span>
<span class="linenos"> 790</span>
<span class="linenos"> 791</span><span class="sd">        # Import RGB image</span>
<span class="linenos"> 792</span><span class="sd">        image = skim.data.cat().astype(float)</span>
<span class="linenos"> 793</span><span class="sd">        print(image.shape)  # (300, 451, 3)</span>
<span class="linenos"> 794</span>
<span class="linenos"> 795</span><span class="sd">        # Move color-stacking axis to front (needed for pyxu stacking convention)</span>
<span class="linenos"> 796</span><span class="sd">        image = np.moveaxis(image, 2, 0)</span>
<span class="linenos"> 797</span><span class="sd">        print(image.shape)  # (3, 300, 451)</span>
<span class="linenos"> 798</span>
<span class="linenos"> 799</span><span class="sd">        # Instantiate diffusion operator</span>
<span class="linenos"> 800</span><span class="sd">        edge_enh_diffop = pyxop.AnisEdgeEnhancingDiffusionOp(dim_shape=(3, 300, 451), beta=10)</span>
<span class="linenos"> 801</span>
<span class="linenos"> 802</span><span class="sd">        # Define PGD solver, with stopping criterion and starting point x0</span>
<span class="linenos"> 803</span><span class="sd">        stop_crit = pystop.MaxIter(n=100)</span>
<span class="linenos"> 804</span>
<span class="linenos"> 805</span><span class="sd">        # Perform 50 gradient flow iterations starting from x0</span>
<span class="linenos"> 806</span><span class="sd">        PGD = pysol.PGD(f=edge_enh_diffop, show_progress=False, verbosity=100)</span>
<span class="linenos"> 807</span><span class="sd">        PGD.fit(**dict(mode=pysolver.SolverMode.BLOCK, x0=image, stop_crit=stop_crit,</span>
<span class="linenos"> 808</span><span class="sd">                       tau=2 / edge_enh_diffop.diff_lipschitz))</span>
<span class="linenos"> 809</span><span class="sd">        edge_enh_image = PGD.solution()</span>
<span class="linenos"> 810</span>
<span class="linenos"> 811</span><span class="sd">        # Reshape images for plotting.</span>
<span class="linenos"> 812</span><span class="sd">        image = np.moveaxis(image, 0, 2)</span>
<span class="linenos"> 813</span><span class="sd">        edge_enh_image = np.moveaxis(edge_enh_image, 0, 2)</span>
<span class="linenos"> 814</span>
<span class="linenos"> 815</span><span class="sd">        # Plot</span>
<span class="linenos"> 816</span><span class="sd">        fig, ax = plt.subplots(1, 2, figsize=(10, 5))</span>
<span class="linenos"> 817</span><span class="sd">        ax[0].imshow(image.astype(int))</span>
<span class="linenos"> 818</span><span class="sd">        ax[0].set_title(&quot;Image&quot;, fontsize=15)</span>
<span class="linenos"> 819</span><span class="sd">        ax[0].axis(&#39;off&#39;)</span>
<span class="linenos"> 820</span><span class="sd">        ax[1].imshow(edge_enh_image.astype(int))</span>
<span class="linenos"> 821</span><span class="sd">        ax[1].set_title(&quot;100 iterations Anis. Edge Enhancing&quot;, fontsize=15)</span>
<span class="linenos"> 822</span><span class="sd">        ax[1].axis(&#39;off&#39;)</span>
<span class="linenos"> 823</span>
<span class="linenos"> 824</span><span class="sd">    &quot;&quot;&quot;</span>
<span class="linenos"> 825</span>
<span class="linenos"> 826</span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<span class="linenos"> 827</span>        <span class="bp">self</span><span class="p">,</span>
<span class="linenos"> 828</span>        <span class="n">dim_shape</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">NDArrayShape</span><span class="p">,</span>
<span class="linenos"> 829</span>        <span class="n">beta</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">Real</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
<span class="linenos"> 830</span>        <span class="n">m</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">Real</span> <span class="o">=</span> <span class="mf">4.0</span><span class="p">,</span>
<span class="linenos"> 831</span>        <span class="n">sigma_gd_st</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">Real</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
<span class="linenos"> 832</span>        <span class="n">smooth_sigma_st</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">Real</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<span class="linenos"> 833</span>        <span class="n">sampling</span><span class="p">:</span> <span class="n">typ</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">pyct</span><span class="o">.</span><span class="n">Real</span><span class="p">,</span> <span class="n">cabc</span><span class="o">.</span><span class="n">Sequence</span><span class="p">[</span><span class="n">pyct</span><span class="o">.</span><span class="n">Real</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<span class="linenos"> 834</span>        <span class="n">freezing_arr</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">NDArray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="linenos"> 835</span>        <span class="n">matrix_based_impl</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="linenos"> 836</span>        <span class="n">gpu</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="linenos"> 837</span>        <span class="n">dtype</span><span class="p">:</span> <span class="n">typ</span><span class="o">.</span><span class="n">Optional</span><span class="p">[</span><span class="n">pyct</span><span class="o">.</span><span class="n">DType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="linenos"> 838</span>    <span class="p">):</span>
<span class="linenos"> 839</span>        <span class="n">gradient</span> <span class="o">=</span> <span class="n">pydiff</span><span class="o">.</span><span class="n">Gradient</span><span class="p">(</span>
<span class="linenos"> 840</span>            <span class="n">dim_shape</span><span class="o">=</span><span class="n">dim_shape</span><span class="p">,</span>
<span class="linenos"> 841</span>            <span class="n">directions</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
<span class="linenos"> 842</span>            <span class="n">diff_method</span><span class="o">=</span><span class="s2">&quot;fd&quot;</span><span class="p">,</span>
<span class="linenos"> 843</span>            <span class="n">scheme</span><span class="o">=</span><span class="s2">&quot;forward&quot;</span><span class="p">,</span>
<span class="linenos"> 844</span>            <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;symmetric&quot;</span><span class="p">,</span>
<span class="linenos"> 845</span>            <span class="n">sampling</span><span class="o">=</span><span class="n">sampling</span><span class="p">,</span>
<span class="linenos"> 846</span>            <span class="n">gpu</span><span class="o">=</span><span class="n">gpu</span><span class="p">,</span>
<span class="linenos"> 847</span>            <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
<span class="linenos"> 848</span>        <span class="p">)</span>
<span class="linenos"> 849</span>        <span class="n">structure_tensor</span> <span class="o">=</span> <span class="n">pyfilt</span><span class="o">.</span><span class="n">StructureTensor</span><span class="p">(</span>
<span class="linenos"> 850</span>            <span class="n">dim_shape</span><span class="o">=</span><span class="n">dim_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span>
<span class="linenos"> 851</span>            <span class="n">diff_method</span><span class="o">=</span><span class="s2">&quot;gd&quot;</span><span class="p">,</span>
<span class="linenos"> 852</span>            <span class="n">smooth_sigma</span><span class="o">=</span><span class="n">smooth_sigma_st</span><span class="p">,</span>
<span class="linenos"> 853</span>            <span class="n">sigma</span><span class="o">=</span><span class="n">sigma_gd_st</span><span class="p">,</span>
<span class="linenos"> 854</span>            <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;symmetric&quot;</span><span class="p">,</span>
<span class="linenos"> 855</span>            <span class="n">sampling</span><span class="o">=</span><span class="n">sampling</span><span class="p">,</span>
<span class="linenos"> 856</span>            <span class="n">gpu</span><span class="o">=</span><span class="n">gpu</span><span class="p">,</span>
<span class="linenos"> 857</span>            <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
<span class="linenos"> 858</span>        <span class="p">)</span>
<span class="linenos"> 859</span>        <span class="n">edge_enh_diffusion_coeff</span> <span class="o">=</span> <span class="n">DiffusionCoeffAnisoEdgeEnhancing</span><span class="p">(</span>
<span class="linenos"> 860</span>            <span class="n">dim_shape</span><span class="o">=</span><span class="n">dim_shape</span><span class="p">,</span> <span class="n">structure_tensor</span><span class="o">=</span><span class="n">structure_tensor</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="n">beta</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="n">m</span>
<span class="linenos"> 861</span>        <span class="p">)</span>
<span class="linenos"> 862</span>        <span class="bp">self</span><span class="o">.</span><span class="n">freezing_arr</span> <span class="o">=</span> <span class="n">freezing_arr</span>
<span class="linenos"> 863</span>        <span class="k">if</span> <span class="n">freezing_arr</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos"> 864</span>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">freezing_arr</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">dim_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
<span class="linenos"> 865</span>                <span class="n">xp</span> <span class="o">=</span> <span class="n">pycu</span><span class="o">.</span><span class="n">get_array_module</span><span class="p">(</span><span class="n">freezing_arr</span><span class="p">)</span>
<span class="linenos"> 866</span>                <span class="bp">self</span><span class="o">.</span><span class="n">freezing_arr</span> <span class="o">=</span> <span class="n">xp</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">freezing_arr</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="linenos"> 867</span>            <span class="n">edge_enh_diffusion_coeff</span><span class="o">.</span><span class="n">freeze</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">freezing_arr</span><span class="p">)</span>
<span class="linenos"> 868</span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
<span class="linenos"> 869</span>            <span class="n">dim_shape</span><span class="p">,</span>
<span class="linenos"> 870</span>            <span class="n">gradient</span><span class="o">=</span><span class="n">gradient</span><span class="p">,</span>
<span class="linenos"> 871</span>            <span class="n">diffusion_coefficient</span><span class="o">=</span><span class="n">edge_enh_diffusion_coeff</span><span class="p">,</span>
<span class="linenos"> 872</span>            <span class="n">matrix_based_impl</span><span class="o">=</span><span class="n">matrix_based_impl</span><span class="p">,</span>
<span class="linenos"> 873</span>            <span class="n">gpu</span><span class="o">=</span><span class="n">gpu</span><span class="p">,</span>
<span class="linenos"> 874</span>            <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
<span class="linenos"> 875</span>        <span class="p">)</span>
<span class="linenos"> 876</span>        <span class="c1"># initialize lipschitz constants. should this be done instead inside _DiffusionOp.__init__ ??</span>
<span class="linenos"> 877</span>        <span class="bp">self</span><span class="o">.</span><span class="n">diff_lipschitz</span> <span class="o">=</span> <span class="n">gradient</span><span class="o">.</span><span class="n">lipschitz</span><span class="o">**</span><span class="mi">2</span>
<span class="linenos"> 878</span>
<span class="linenos"> 879</span>    <span class="c1"># @pycrt.enforce_precision(i=&quot;arr&quot;)</span>
<span class="linenos"> 880</span>    <span class="c1"># @pycu.vectorize(&quot;arr&quot;)</span>
<span class="linenos"> 881</span>    <span class="k">def</span><span class="w"> </span><span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arr</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">NDArray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pyct</span><span class="o">.</span><span class="n">Real</span><span class="p">:</span>
<span class="linenos"> 882</span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">freezing_arr</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos"> 883</span>            <span class="n">xp</span> <span class="o">=</span> <span class="n">pycu</span><span class="o">.</span><span class="n">get_array_module</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
<span class="linenos"> 884</span>            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_divergence_term</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>  <span class="c1"># (batch,nchannels,nx,ny)</span>
<span class="linenos"> 885</span>            <span class="k">return</span> <span class="n">xp</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;...jkl,...jkl-&gt;...&quot;</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">arr</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>  <span class="c1"># (batch,)</span>
<span class="linenos"> 886</span>        <span class="k">else</span><span class="p">:</span>
<span class="linenos"> 887</span>            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
<span class="linenos"> 888</span>                <span class="s2">&quot;&#39;apply()&#39; method not defined for AnisEdgeEnhancingDiffusionOp if no `freezing_arr` is passed.&quot;</span>
<span class="linenos"> 889</span>            <span class="p">)</span></div>

<span class="linenos"> 890</span>
<span class="linenos"> 891</span>
<div class="viewcode-block" id="AnisCoherenceEnhancingDiffusionOp">
<a class="viewcode-back" href="../../../../api/operator.html#pyxu_diffops.operator.AnisCoherenceEnhancingDiffusionOp">[docs]</a>
<span class="linenos"> 892</span><span class="k">class</span><span class="w"> </span><span class="nc">AnisCoherenceEnhancingDiffusionOp</span><span class="p">(</span><span class="n">_Diffusion</span><span class="p">):</span>
<span class="linenos"> 893</span><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="linenos"> 894</span><span class="sd">    Anisotropic coherence-enhancing diffusion operator, featuring an inhomogeneous anisotropic diffusion tensor</span>
<span class="linenos"> 895</span><span class="sd">    defined as in [Weickert]_. The diffusion tensor is defined as a function of the</span>
<span class="linenos"> 896</span><span class="sd">    :py:class:`~pyxu.operator.linop.filter.StructureTensor`,</span>
<span class="linenos"> 897</span><span class="sd">    which is a tensor describing the properties of the image in the neighbourhood of each pixel.</span>
<span class="linenos"> 898</span><span class="sd">    This diffusion operator allows coherence enhancement by increasing the flux in the direction of the</span>
<span class="linenos"> 899</span><span class="sd">    eigenvector of the structure tensor with smallest eigenvalue, with an intensity which depends on</span>
<span class="linenos"> 900</span><span class="sd">    the image coherence, which is measured as :math:`(e_0-e_1)^2`. Stronger coherence leads to stronger smoothing.</span>
<span class="linenos"> 901</span>
<span class="linenos"> 902</span><span class="sd">    The gradient of the operator reads :math:`-\mathrm{div}(\mathbf{D}(\mathbf{f})\boldsymbol{\nabla}\mathbf{f})`.</span>
<span class="linenos"> 903</span>
<span class="linenos"> 904</span><span class="sd">    Let :math:`\mathbf{v}_0^i,\mathbf{v}_1^i` be the eigenvectors of the :math:`i`-th pixel structure tensor</span>
<span class="linenos"> 905</span><span class="sd">    :math:`S_i`, with eigenvalues :math:`e_0^i, e_1^i` sorted in decreasing order. The diffusion tensor is defined,</span>
<span class="linenos"> 906</span><span class="sd">    for the :math:`i`-th pixel, as the symmetric positive definite tensor:</span>
<span class="linenos"> 907</span>
<span class="linenos"> 908</span><span class="sd">    .. math::</span>
<span class="linenos"> 909</span>
<span class="linenos"> 910</span><span class="sd">        \big(\mathbf{D}(\mathbf{f})\big)_i = \lambda_0^i\mathbf{v}_0^i(\mathbf{v}_0^i)^T+\lambda_1^i\mathbf{v}_1^i(\mathbf{v}_1^i)^T,</span>
<span class="linenos"> 911</span>
<span class="linenos"> 912</span><span class="sd">    where the smoothing intensities along the two eigendirections are defined, to achieve coherence-enhancing, as</span>
<span class="linenos"> 913</span>
<span class="linenos"> 914</span><span class="sd">    .. math::</span>
<span class="linenos"> 915</span><span class="sd">        \lambda_0^i &amp;= \alpha,\\</span>
<span class="linenos"> 916</span><span class="sd">        \lambda_1^i &amp;=  h(e_0^i, e_1^i) :=</span>
<span class="linenos"> 917</span><span class="sd">        \begin{cases}</span>
<span class="linenos"> 918</span><span class="sd">              \alpha &amp; \text{if } e_0^i=e_1^i \\</span>
<span class="linenos"> 919</span><span class="sd">               \alpha + (1-\alpha) \exp \big(\frac{-C}{(e_0^i-e_1^i)^{2m}}\big) &amp; \text{otherwise},</span>
<span class="linenos"> 920</span><span class="sd">        \end{cases}</span>
<span class="linenos"> 921</span>
<span class="linenos"> 922</span><span class="sd">    where :math:`\alpha \in (0, 1)` controls the smoothing intensity along the first eigendirection, :math:`m` controls</span>
<span class="linenos"> 923</span><span class="sd">    the decay rate of :math:`\lambda_0^i` as a function of :math:`(e_0^i-e_1^i)`, and :math:`C\in\mathbb{R}` is a constant.</span>
<span class="linenos"> 924</span>
<span class="linenos"> 925</span><span class="sd">    For regions with low coherence, smoothing is performed uniformly along all</span>
<span class="linenos"> 926</span><span class="sd">    directions with intensity :math:`\lambda_1^i \approx \lambda_0^i = \alpha`. For regions with high coherence, we have</span>
<span class="linenos"> 927</span><span class="sd">    :math:`\lambda_1^i \approx 1 &gt; \lambda_0^i = \alpha`, hence the smoothing intensity is higher in the direction</span>
<span class="linenos"> 928</span><span class="sd">    orthogonal to the (locally averaged) gradient.</span>
<span class="linenos"> 929</span>
<span class="linenos"> 930</span><span class="sd">    In general, the diffusion operator does not admit a potential. However, if the diffusion tensor is evaluated</span>
<span class="linenos"> 931</span><span class="sd">    at some image :math:`\tilde{\mathbf{f}}` and kept fixed to :math:`\mathbf{D}(\tilde{\mathbf{f}})`, the operator</span>
<span class="linenos"> 932</span><span class="sd">    derives from the potential :math:`\Vert\sqrt{\mathbf{D}(\tilde{\mathbf{f}})}\boldsymbol{\nabla}\mathbf{f}\Vert_2^2`.</span>
<span class="linenos"> 933</span><span class="sd">    By doing so, the smoothing directions and intensities are fixed according to the features of an image of interest.</span>
<span class="linenos"> 934</span><span class="sd">    This can be achieved passing a *freezing array* at initialization. In such cases, a *matrix-based implementation*</span>
<span class="linenos"> 935</span><span class="sd">    is recommended for efficiency.</span>
<span class="linenos"> 936</span>
<span class="linenos"> 937</span><span class="sd">    Parameters</span>
<span class="linenos"> 938</span><span class="sd">    ----------</span>
<span class="linenos"> 939</span><span class="sd">    dim_shape: NDArrayShape</span>
<span class="linenos"> 940</span><span class="sd">        Shape of the input array.</span>
<span class="linenos"> 941</span><span class="sd">    alpha: Real</span>
<span class="linenos"> 942</span><span class="sd">        Anisotropic parameter, determining intensity of smoothing inhibition along the (locally averaged) image gradient.</span>
<span class="linenos"> 943</span><span class="sd">        Defaults to 1e-1.</span>
<span class="linenos"> 944</span><span class="sd">    m: Real</span>
<span class="linenos"> 945</span><span class="sd">        Decay parameter, determines how quickly the smoothing effect changes as a function of :math:`e_0^i/\beta`.</span>
<span class="linenos"> 946</span><span class="sd">        Defaults to 1.</span>
<span class="linenos"> 947</span><span class="sd">    sigma_gd_st: Real</span>
<span class="linenos"> 948</span><span class="sd">       Gaussian width of the gaussian derivative involved in the structure tensor computation</span>
<span class="linenos"> 949</span><span class="sd">       (if `diff_method_struct_tens=&quot;gd&quot;`). Defaults to 2.</span>
<span class="linenos"> 950</span><span class="sd">    smooth_sigma_st: Real</span>
<span class="linenos"> 951</span><span class="sd">       Width of the Gaussian filter smoothing the structure tensor (local averaging). Defaults to 4.</span>
<span class="linenos"> 952</span><span class="sd">    sampling: Real, list[Real]</span>
<span class="linenos"> 953</span><span class="sd">            Sampling step (i.e. distance between two consecutive elements of an array).</span>
<span class="linenos"> 954</span><span class="sd">            Defaults to 1.</span>
<span class="linenos"> 955</span><span class="sd">    diff_method_struct_tens: str</span>
<span class="linenos"> 956</span><span class="sd">                            Differentiation method for structure tensor computation. Must be either &#39;gd&#39; or &#39;fd&#39;.</span>
<span class="linenos"> 957</span><span class="sd">                            Defaults to &#39;gd&#39;.</span>
<span class="linenos"> 958</span><span class="sd">    freezing_arr: NDArray</span>
<span class="linenos"> 959</span><span class="sd">                Array at which the diffusion tensor is evaluated and then frozen.</span>
<span class="linenos"> 960</span><span class="sd">    matrix_based_impl: bool</span>
<span class="linenos"> 961</span><span class="sd">                Whether to use matrix based implementation or not. Defaults to False. Recommended to set `True` if</span>
<span class="linenos"> 962</span><span class="sd">                a ``freezing_arr`` is passed.</span>
<span class="linenos"> 963</span>
<span class="linenos"> 964</span><span class="sd">    Returns</span>
<span class="linenos"> 965</span><span class="sd">    -------</span>
<span class="linenos"> 966</span><span class="sd">    op: OpT</span>
<span class="linenos"> 967</span><span class="sd">            Anisotropic coherence-enhancing diffusion operator.</span>
<span class="linenos"> 968</span>
<span class="linenos"> 969</span><span class="sd">    Example</span>
<span class="linenos"> 970</span><span class="sd">    -------</span>
<span class="linenos"> 971</span>
<span class="linenos"> 972</span><span class="sd">    .. plot::</span>
<span class="linenos"> 973</span>
<span class="linenos"> 974</span><span class="sd">        import numpy as np</span>
<span class="linenos"> 975</span><span class="sd">        import matplotlib.pyplot as plt</span>
<span class="linenos"> 976</span><span class="sd">        import pyxu.opt.solver as pysol</span>
<span class="linenos"> 977</span><span class="sd">        import pyxu.abc.solver as pysolver</span>
<span class="linenos"> 978</span><span class="sd">        import pyxu.opt.stop as pystop</span>
<span class="linenos"> 979</span><span class="sd">        import pyxu_diffops.operator as pyxop</span>
<span class="linenos"> 980</span><span class="sd">        import skimage as skim</span>
<span class="linenos"> 981</span>
<span class="linenos"> 982</span><span class="sd">        # Import RGB image</span>
<span class="linenos"> 983</span><span class="sd">        image = skim.data.cat().astype(float)</span>
<span class="linenos"> 984</span><span class="sd">        print(image.shape)  # (300, 451, 3)</span>
<span class="linenos"> 985</span>
<span class="linenos"> 986</span><span class="sd">        # Move color-stacking axis to front (needed for pyxu stacking convention)</span>
<span class="linenos"> 987</span><span class="sd">        image = np.moveaxis(image, 2, 0)</span>
<span class="linenos"> 988</span><span class="sd">        print(image.shape)  # (3, 300, 451)</span>
<span class="linenos"> 989</span>
<span class="linenos"> 990</span><span class="sd">        # Instantiate diffusion operator</span>
<span class="linenos"> 991</span><span class="sd">        coh_enh_diffop = pyxop.AnisCoherenceEnhancingDiffusionOp(dim_shape=(3, 300, 451), alpha=1e-3)</span>
<span class="linenos"> 992</span>
<span class="linenos"> 993</span><span class="sd">        # Define PGD solver, with stopping criterion and starting point x0</span>
<span class="linenos"> 994</span><span class="sd">        stop_crit = pystop.MaxIter(n=100)</span>
<span class="linenos"> 995</span>
<span class="linenos"> 996</span><span class="sd">        # Perform 50 gradient flow iterations starting from x0</span>
<span class="linenos"> 997</span><span class="sd">        PGD = pysol.PGD(f=coh_enh_diffop, show_progress=False, verbosity=100)</span>
<span class="linenos"> 998</span><span class="sd">        PGD.fit(**dict(mode=pysolver.SolverMode.BLOCK, x0=image, stop_crit=stop_crit,</span>
<span class="linenos"> 999</span><span class="sd">                       tau=2 / coh_enh_diffop.diff_lipschitz))</span>
<span class="linenos">1000</span><span class="sd">        coh_enh_image = PGD.solution()</span>
<span class="linenos">1001</span>
<span class="linenos">1002</span><span class="sd">        # Reshape images for plotting.</span>
<span class="linenos">1003</span><span class="sd">        image = np.moveaxis(image, 0, 2)</span>
<span class="linenos">1004</span><span class="sd">        coh_enh_image = np.moveaxis(coh_enh_image, 0, 2)</span>
<span class="linenos">1005</span>
<span class="linenos">1006</span><span class="sd">        # Plot</span>
<span class="linenos">1007</span><span class="sd">        fig, ax = plt.subplots(1, 2, figsize=(10, 5))</span>
<span class="linenos">1008</span><span class="sd">        ax[0].imshow(image.astype(int))</span>
<span class="linenos">1009</span><span class="sd">        ax[0].set_title(&quot;Image&quot;, fontsize=15)</span>
<span class="linenos">1010</span><span class="sd">        ax[0].axis(&#39;off&#39;)</span>
<span class="linenos">1011</span><span class="sd">        ax[1].imshow(coh_enh_image.astype(int))</span>
<span class="linenos">1012</span><span class="sd">        ax[1].set_title(&quot;100 iterations Anis. Coherence Enhancing&quot;, fontsize=15)</span>
<span class="linenos">1013</span><span class="sd">        ax[1].axis(&#39;off&#39;)</span>
<span class="linenos">1014</span>
<span class="linenos">1015</span><span class="sd">    &quot;&quot;&quot;</span>
<span class="linenos">1016</span>
<span class="linenos">1017</span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<span class="linenos">1018</span>        <span class="bp">self</span><span class="p">,</span>
<span class="linenos">1019</span>        <span class="n">dim_shape</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">NDArrayShape</span><span class="p">,</span>
<span class="linenos">1020</span>        <span class="n">alpha</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">Real</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
<span class="linenos">1021</span>        <span class="n">m</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">Real</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<span class="linenos">1022</span>        <span class="n">sigma_gd_st</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">Real</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
<span class="linenos">1023</span>        <span class="n">smooth_sigma_st</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">Real</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
<span class="linenos">1024</span>        <span class="n">sampling</span><span class="p">:</span> <span class="n">typ</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">pyct</span><span class="o">.</span><span class="n">Real</span><span class="p">,</span> <span class="n">cabc</span><span class="o">.</span><span class="n">Sequence</span><span class="p">[</span><span class="n">pyct</span><span class="o">.</span><span class="n">Real</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<span class="linenos">1025</span>        <span class="n">diff_method_struct_tens</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;gd&quot;</span><span class="p">,</span>
<span class="linenos">1026</span>        <span class="n">freezing_arr</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">NDArray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="linenos">1027</span>        <span class="n">matrix_based_impl</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="linenos">1028</span>        <span class="n">gpu</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="linenos">1029</span>        <span class="n">dtype</span><span class="p">:</span> <span class="n">typ</span><span class="o">.</span><span class="n">Optional</span><span class="p">[</span><span class="n">pyct</span><span class="o">.</span><span class="n">DType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="linenos">1030</span>    <span class="p">):</span>
<span class="linenos">1031</span>        <span class="n">gradient</span> <span class="o">=</span> <span class="n">pydiff</span><span class="o">.</span><span class="n">Gradient</span><span class="p">(</span>
<span class="linenos">1032</span>            <span class="n">dim_shape</span><span class="o">=</span><span class="n">dim_shape</span><span class="p">,</span>
<span class="linenos">1033</span>            <span class="n">directions</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
<span class="linenos">1034</span>            <span class="n">diff_method</span><span class="o">=</span><span class="s2">&quot;fd&quot;</span><span class="p">,</span>
<span class="linenos">1035</span>            <span class="n">scheme</span><span class="o">=</span><span class="s2">&quot;forward&quot;</span><span class="p">,</span>
<span class="linenos">1036</span>            <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;symmetric&quot;</span><span class="p">,</span>
<span class="linenos">1037</span>            <span class="n">sampling</span><span class="o">=</span><span class="n">sampling</span><span class="p">,</span>
<span class="linenos">1038</span>            <span class="n">gpu</span><span class="o">=</span><span class="n">gpu</span><span class="p">,</span>
<span class="linenos">1039</span>            <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
<span class="linenos">1040</span>        <span class="p">)</span>
<span class="linenos">1041</span>        <span class="n">structure_tensor</span> <span class="o">=</span> <span class="n">pyfilt</span><span class="o">.</span><span class="n">StructureTensor</span><span class="p">(</span>
<span class="linenos">1042</span>            <span class="n">dim_shape</span><span class="o">=</span><span class="n">dim_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span>
<span class="linenos">1043</span>            <span class="n">diff_method</span><span class="o">=</span><span class="n">diff_method_struct_tens</span><span class="p">,</span>
<span class="linenos">1044</span>            <span class="n">smooth_sigma</span><span class="o">=</span><span class="n">smooth_sigma_st</span><span class="p">,</span>
<span class="linenos">1045</span>            <span class="n">sigma</span><span class="o">=</span><span class="n">sigma_gd_st</span><span class="p">,</span>
<span class="linenos">1046</span>            <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;symmetric&quot;</span><span class="p">,</span>
<span class="linenos">1047</span>            <span class="n">sampling</span><span class="o">=</span><span class="n">sampling</span><span class="p">,</span>
<span class="linenos">1048</span>            <span class="n">gpu</span><span class="o">=</span><span class="n">gpu</span><span class="p">,</span>
<span class="linenos">1049</span>            <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
<span class="linenos">1050</span>        <span class="p">)</span>
<span class="linenos">1051</span>        <span class="n">coh_enh_diffusion_coeff</span> <span class="o">=</span> <span class="n">DiffusionCoeffAnisoCoherenceEnhancing</span><span class="p">(</span>
<span class="linenos">1052</span>            <span class="n">dim_shape</span><span class="o">=</span><span class="n">dim_shape</span><span class="p">,</span> <span class="n">structure_tensor</span><span class="o">=</span><span class="n">structure_tensor</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="n">m</span>
<span class="linenos">1053</span>        <span class="p">)</span>
<span class="linenos">1054</span>        <span class="bp">self</span><span class="o">.</span><span class="n">freezing_arr</span> <span class="o">=</span> <span class="n">freezing_arr</span>
<span class="linenos">1055</span>        <span class="k">if</span> <span class="n">freezing_arr</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos">1056</span>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">freezing_arr</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">dim_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
<span class="linenos">1057</span>                <span class="n">xp</span> <span class="o">=</span> <span class="n">pycu</span><span class="o">.</span><span class="n">get_array_module</span><span class="p">(</span><span class="n">freezing_arr</span><span class="p">)</span>
<span class="linenos">1058</span>                <span class="bp">self</span><span class="o">.</span><span class="n">freezing_arr</span> <span class="o">=</span> <span class="n">xp</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">freezing_arr</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="linenos">1059</span>            <span class="n">coh_enh_diffusion_coeff</span><span class="o">.</span><span class="n">freeze</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">freezing_arr</span><span class="p">)</span>
<span class="linenos">1060</span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
<span class="linenos">1061</span>            <span class="n">dim_shape</span><span class="p">,</span>
<span class="linenos">1062</span>            <span class="n">gradient</span><span class="o">=</span><span class="n">gradient</span><span class="p">,</span>
<span class="linenos">1063</span>            <span class="n">diffusion_coefficient</span><span class="o">=</span><span class="n">coh_enh_diffusion_coeff</span><span class="p">,</span>
<span class="linenos">1064</span>            <span class="n">matrix_based_impl</span><span class="o">=</span><span class="n">matrix_based_impl</span><span class="p">,</span>
<span class="linenos">1065</span>            <span class="n">gpu</span><span class="o">=</span><span class="n">gpu</span><span class="p">,</span>
<span class="linenos">1066</span>            <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
<span class="linenos">1067</span>        <span class="p">)</span>
<span class="linenos">1068</span>        <span class="c1"># initialize lipschitz constants. should this be done instead inside _DiffusionOp.__init__ ??</span>
<span class="linenos">1069</span>        <span class="bp">self</span><span class="o">.</span><span class="n">diff_lipschitz</span> <span class="o">=</span> <span class="n">gradient</span><span class="o">.</span><span class="n">lipschitz</span><span class="o">**</span><span class="mi">2</span>
<span class="linenos">1070</span>
<span class="linenos">1071</span>    <span class="c1"># @pycrt.enforce_precision(i=&quot;arr&quot;)</span>
<span class="linenos">1072</span>    <span class="c1"># @pycu.vectorize(&quot;arr&quot;)</span>
<span class="linenos">1073</span>    <span class="k">def</span><span class="w"> </span><span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arr</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">NDArray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pyct</span><span class="o">.</span><span class="n">Real</span><span class="p">:</span>
<span class="linenos">1074</span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">freezing_arr</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos">1075</span>            <span class="n">xp</span> <span class="o">=</span> <span class="n">pycu</span><span class="o">.</span><span class="n">get_array_module</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
<span class="linenos">1076</span>            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_divergence_term</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>  <span class="c1"># (batch,nchannels,nx,ny)</span>
<span class="linenos">1077</span>            <span class="k">return</span> <span class="n">xp</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;...jkl,...jkl-&gt;...&quot;</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">arr</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>  <span class="c1"># (batch,)</span>
<span class="linenos">1078</span>        <span class="k">else</span><span class="p">:</span>
<span class="linenos">1079</span>            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
<span class="linenos">1080</span>                <span class="s2">&quot;&#39;apply()&#39; method not defined for AnisCoherenceEnhancingDiffusionOp if no `freezing_arr` is passed.&quot;</span>
<span class="linenos">1081</span>            <span class="p">)</span></div>

<span class="linenos">1082</span>
<span class="linenos">1083</span>
<div class="viewcode-block" id="AnisDiffusionOp">
<a class="viewcode-back" href="../../../../api/operator.html#pyxu_diffops.operator.AnisDiffusionOp">[docs]</a>
<span class="linenos">1084</span><span class="k">class</span><span class="w"> </span><span class="nc">AnisDiffusionOp</span><span class="p">(</span><span class="n">_Diffusion</span><span class="p">):</span>
<span class="linenos">1085</span><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="linenos">1086</span><span class="sd">    Anisotropic diffusion operator, featuring an inhomogeneous anisotropic diffusion tensor.</span>
<span class="linenos">1087</span><span class="sd">    The diffusion tensor is defined as a function of the</span>
<span class="linenos">1088</span><span class="sd">    :py:class:`~pyxu.operator.linop.filter.StructureTensor`,</span>
<span class="linenos">1089</span><span class="sd">    which is a tensor describing the properties of the image in the neighbourhood of each pixel.</span>
<span class="linenos">1090</span><span class="sd">    This diffusion operator allows anisotropic smoothing by reducing the flux in the direction of the</span>
<span class="linenos">1091</span><span class="sd">    eigenvector of the structure tensor with largest eigenvalue. Essentially, the (locally averaged)</span>
<span class="linenos">1092</span><span class="sd">    gradient is preserved.</span>
<span class="linenos">1093</span>
<span class="linenos">1094</span><span class="sd">    The gradient of the operator reads :math:`-\mathrm{div}(\mathbf{D}(\mathbf{f})\boldsymbol{\nabla}\mathbf{f})`.</span>
<span class="linenos">1095</span>
<span class="linenos">1096</span><span class="sd">    Let :math:`\mathbf{v}_0^i,\mathbf{v}_1^i` be the eigenvectors of the :math:`i`-th pixel structure tensor</span>
<span class="linenos">1097</span><span class="sd">    :math:`S_i`, with eigenvalues :math:`e_0^i, e_1^i` sorted in decreasing order. The diffusion tensor is defined,</span>
<span class="linenos">1098</span><span class="sd">    for the :math:`i`-th pixel, as the symmetric positive definite tensor:</span>
<span class="linenos">1099</span>
<span class="linenos">1100</span><span class="sd">    .. math::</span>
<span class="linenos">1101</span><span class="sd">        \big(\mathbf{D}(\mathbf{f})\big)_i = \lambda_0^i\mathbf{v}_0^i(\mathbf{v}_0^i)^T+\lambda_1^i\mathbf{v}_1^i(\mathbf{v}_1^i)^T,</span>
<span class="linenos">1102</span>
<span class="linenos">1103</span><span class="sd">    where the smoothing intensities along the two eigendirections are defined, to achieve anisotropic smoothing, as</span>
<span class="linenos">1104</span>
<span class="linenos">1105</span><span class="sd">    .. math::</span>
<span class="linenos">1106</span><span class="sd">        \lambda_0^i &amp;= \alpha,\\</span>
<span class="linenos">1107</span><span class="sd">        \lambda_1^i &amp;=  1,</span>
<span class="linenos">1108</span>
<span class="linenos">1109</span><span class="sd">    where :math:`\alpha \in (0, 1)` controls the smoothing intensity along the first eigendirection.</span>
<span class="linenos">1110</span>
<span class="linenos">1111</span><span class="sd">    In general, the diffusion operator does not admit a potential. However, if the diffusion tensor is evaluated</span>
<span class="linenos">1112</span><span class="sd">    at some image :math:`\tilde{\mathbf{f}}` and kept fixed to :math:`\mathbf{D}(\tilde{\mathbf{f}})`, the operator</span>
<span class="linenos">1113</span><span class="sd">    derives from the potential :math:`\Vert\sqrt{\mathbf{D}(\tilde{\mathbf{f}})}\boldsymbol{\nabla}\mathbf{f}\Vert_2^2`.</span>
<span class="linenos">1114</span><span class="sd">    By doing so, the smoothing directions and intensities are fixed according to the features of an image of interest.</span>
<span class="linenos">1115</span><span class="sd">    This can be achieved passing a *freezing array* at initialization. In such cases, a *matrix-based implementation*</span>
<span class="linenos">1116</span><span class="sd">    is recommended for efficiency.</span>
<span class="linenos">1117</span>
<span class="linenos">1118</span><span class="sd">    Parameters</span>
<span class="linenos">1119</span><span class="sd">    ----------</span>
<span class="linenos">1120</span><span class="sd">    dim_shape: NDArrayShape</span>
<span class="linenos">1121</span><span class="sd">        Shape of the input array.</span>
<span class="linenos">1122</span><span class="sd">    alpha: Real</span>
<span class="linenos">1123</span><span class="sd">        Anisotropic parameter, determining intensity of smoothing inhibition along the (locally averaged) image gradient.</span>
<span class="linenos">1124</span><span class="sd">        Defaults to 1e-1.</span>
<span class="linenos">1125</span><span class="sd">    sigma_gd_st: Real</span>
<span class="linenos">1126</span><span class="sd">       Gaussian width of the gaussian derivative involved in the structure tensor computation</span>
<span class="linenos">1127</span><span class="sd">       (if `diff_method_struct_tens=&quot;gd&quot;`). Defaults to 1.</span>
<span class="linenos">1128</span><span class="sd">    smooth_sigma_st: Real</span>
<span class="linenos">1129</span><span class="sd">       Width of the Gaussian filter smoothing the structure tensor (local averaging). Defaults to 1.</span>
<span class="linenos">1130</span><span class="sd">    sampling: Real, list[Real]</span>
<span class="linenos">1131</span><span class="sd">            Sampling step (i.e. distance between two consecutive elements of an array).</span>
<span class="linenos">1132</span><span class="sd">            Defaults to 1.</span>
<span class="linenos">1133</span><span class="sd">    diff_method_struct_tens: str</span>
<span class="linenos">1134</span><span class="sd">                            Differentiation method for structure tensor computation. Must be either &#39;gd&#39; or &#39;fd&#39;.</span>
<span class="linenos">1135</span><span class="sd">                            Defaults ot &#39;fd&#39;.</span>
<span class="linenos">1136</span><span class="sd">    freezing_arr: NDArray</span>
<span class="linenos">1137</span><span class="sd">                Array at which the diffusion tensor is evaluated and then frozen.</span>
<span class="linenos">1138</span><span class="sd">    matrix_based_impl: bool</span>
<span class="linenos">1139</span><span class="sd">                Whether to use matrix based implementation or not. Defaults to False. Recommended to set `True` if</span>
<span class="linenos">1140</span><span class="sd">                a ``freezing_arr`` is passed.</span>
<span class="linenos">1141</span>
<span class="linenos">1142</span><span class="sd">    Returns</span>
<span class="linenos">1143</span><span class="sd">    -------</span>
<span class="linenos">1144</span><span class="sd">    op: OpT</span>
<span class="linenos">1145</span><span class="sd">            Anisotropic diffusion operator.</span>
<span class="linenos">1146</span>
<span class="linenos">1147</span><span class="sd">    &quot;&quot;&quot;</span>
<span class="linenos">1148</span>
<span class="linenos">1149</span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<span class="linenos">1150</span>        <span class="bp">self</span><span class="p">,</span>
<span class="linenos">1151</span>        <span class="n">dim_shape</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">NDArrayShape</span><span class="p">,</span>
<span class="linenos">1152</span>        <span class="n">alpha</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">Real</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
<span class="linenos">1153</span>        <span class="n">sigma_gd_st</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">Real</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<span class="linenos">1154</span>        <span class="n">sampling</span><span class="p">:</span> <span class="n">typ</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">pyct</span><span class="o">.</span><span class="n">Real</span><span class="p">,</span> <span class="n">cabc</span><span class="o">.</span><span class="n">Sequence</span><span class="p">[</span><span class="n">pyct</span><span class="o">.</span><span class="n">Real</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<span class="linenos">1155</span>        <span class="n">diff_method_struct_tens</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;fd&quot;</span><span class="p">,</span>
<span class="linenos">1156</span>        <span class="n">freezing_arr</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">NDArray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="linenos">1157</span>        <span class="n">matrix_based_impl</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="linenos">1158</span>        <span class="n">gpu</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="linenos">1159</span>        <span class="n">dtype</span><span class="p">:</span> <span class="n">typ</span><span class="o">.</span><span class="n">Optional</span><span class="p">[</span><span class="n">pyct</span><span class="o">.</span><span class="n">DType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="linenos">1160</span>    <span class="p">):</span>
<span class="linenos">1161</span>        <span class="n">gradient</span> <span class="o">=</span> <span class="n">pydiff</span><span class="o">.</span><span class="n">Gradient</span><span class="p">(</span>
<span class="linenos">1162</span>            <span class="n">dim_shape</span><span class="o">=</span><span class="n">dim_shape</span><span class="p">,</span>
<span class="linenos">1163</span>            <span class="n">directions</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
<span class="linenos">1164</span>            <span class="n">diff_method</span><span class="o">=</span><span class="s2">&quot;fd&quot;</span><span class="p">,</span>
<span class="linenos">1165</span>            <span class="n">scheme</span><span class="o">=</span><span class="s2">&quot;forward&quot;</span><span class="p">,</span>
<span class="linenos">1166</span>            <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;symmetric&quot;</span><span class="p">,</span>
<span class="linenos">1167</span>            <span class="n">sampling</span><span class="o">=</span><span class="n">sampling</span><span class="p">,</span>
<span class="linenos">1168</span>            <span class="n">gpu</span><span class="o">=</span><span class="n">gpu</span><span class="p">,</span>
<span class="linenos">1169</span>            <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
<span class="linenos">1170</span>        <span class="p">)</span>
<span class="linenos">1171</span>        <span class="n">structure_tensor</span> <span class="o">=</span> <span class="n">pyfilt</span><span class="o">.</span><span class="n">StructureTensor</span><span class="p">(</span>
<span class="linenos">1172</span>            <span class="n">dim_shape</span><span class="o">=</span><span class="n">dim_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span>
<span class="linenos">1173</span>            <span class="n">diff_method</span><span class="o">=</span><span class="n">diff_method_struct_tens</span><span class="p">,</span>
<span class="linenos">1174</span>            <span class="n">smooth_sigma</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">1175</span>            <span class="n">sigma</span><span class="o">=</span><span class="n">sigma_gd_st</span><span class="p">,</span>
<span class="linenos">1176</span>            <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;symmetric&quot;</span><span class="p">,</span>
<span class="linenos">1177</span>            <span class="n">sampling</span><span class="o">=</span><span class="n">sampling</span><span class="p">,</span>
<span class="linenos">1178</span>            <span class="n">gpu</span><span class="o">=</span><span class="n">gpu</span><span class="p">,</span>
<span class="linenos">1179</span>            <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
<span class="linenos">1180</span>        <span class="p">)</span>
<span class="linenos">1181</span>        <span class="n">anis_diffusion_coeff</span> <span class="o">=</span> <span class="n">DiffusionCoeffAnisotropic</span><span class="p">(</span>
<span class="linenos">1182</span>            <span class="n">dim_shape</span><span class="o">=</span><span class="n">dim_shape</span><span class="p">,</span> <span class="n">structure_tensor</span><span class="o">=</span><span class="n">structure_tensor</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span>
<span class="linenos">1183</span>        <span class="p">)</span>
<span class="linenos">1184</span>        <span class="bp">self</span><span class="o">.</span><span class="n">freezing_arr</span> <span class="o">=</span> <span class="n">freezing_arr</span>
<span class="linenos">1185</span>        <span class="k">if</span> <span class="n">freezing_arr</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos">1186</span>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">freezing_arr</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">dim_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
<span class="linenos">1187</span>                <span class="n">xp</span> <span class="o">=</span> <span class="n">pycu</span><span class="o">.</span><span class="n">get_array_module</span><span class="p">(</span><span class="n">freezing_arr</span><span class="p">)</span>
<span class="linenos">1188</span>                <span class="bp">self</span><span class="o">.</span><span class="n">freezing_arr</span> <span class="o">=</span> <span class="n">xp</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">freezing_arr</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="linenos">1189</span>            <span class="n">anis_diffusion_coeff</span><span class="o">.</span><span class="n">freeze</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">freezing_arr</span><span class="p">)</span>
<span class="linenos">1190</span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
<span class="linenos">1191</span>            <span class="n">dim_shape</span><span class="p">,</span>
<span class="linenos">1192</span>            <span class="n">gradient</span><span class="o">=</span><span class="n">gradient</span><span class="p">,</span>
<span class="linenos">1193</span>            <span class="n">diffusion_coefficient</span><span class="o">=</span><span class="n">anis_diffusion_coeff</span><span class="p">,</span>
<span class="linenos">1194</span>            <span class="n">matrix_based_impl</span><span class="o">=</span><span class="n">matrix_based_impl</span><span class="p">,</span>
<span class="linenos">1195</span>            <span class="n">gpu</span><span class="o">=</span><span class="n">gpu</span><span class="p">,</span>
<span class="linenos">1196</span>            <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
<span class="linenos">1197</span>        <span class="p">)</span>
<span class="linenos">1198</span>        <span class="c1"># initialize lipschitz constants. should this be done instead inside _DiffusionOp.__init__ ??</span>
<span class="linenos">1199</span>        <span class="bp">self</span><span class="o">.</span><span class="n">diff_lipschitz</span> <span class="o">=</span> <span class="n">gradient</span><span class="o">.</span><span class="n">lipschitz</span><span class="o">**</span><span class="mi">2</span>
<span class="linenos">1200</span>
<span class="linenos">1201</span>    <span class="c1"># @pycrt.enforce_precision(i=&quot;arr&quot;)</span>
<span class="linenos">1202</span>    <span class="c1"># @pycu.vectorize(&quot;arr&quot;)</span>
<span class="linenos">1203</span>    <span class="k">def</span><span class="w"> </span><span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arr</span><span class="p">:</span> <span class="n">pyct</span><span class="o">.</span><span class="n">NDArray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pyct</span><span class="o">.</span><span class="n">Real</span><span class="p">:</span>
<span class="linenos">1204</span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">freezing_arr</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos">1205</span>            <span class="n">xp</span> <span class="o">=</span> <span class="n">pycu</span><span class="o">.</span><span class="n">get_array_module</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
<span class="linenos">1206</span>            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_divergence_term</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>  <span class="c1"># (batch,nchannels,nx,ny)</span>
<span class="linenos">1207</span>            <span class="k">return</span> <span class="n">xp</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;...jkl,...jkl-&gt;...&quot;</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">arr</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>  <span class="c1"># (batch,)</span>
<span class="linenos">1208</span>        <span class="k">else</span><span class="p">:</span>
<span class="linenos">1209</span>            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;&#39;apply()&#39; method not defined for AnisDiffusionOp if no `freezing_arr` is passed.&quot;</span><span class="p">)</span></div>

<span class="linenos">1210</span>
<span class="linenos">1211</span>
<span class="linenos">1212</span><span class="c1"># class AnisMfiDiffusionOp(_Diffusion):</span>
<span class="linenos">1213</span><span class="c1">#     r&quot;&quot;&quot;</span>
<span class="linenos">1214</span><span class="c1">#     Example</span>
<span class="linenos">1215</span><span class="c1">#     -------</span>
<span class="linenos">1216</span><span class="c1">#</span>
<span class="linenos">1217</span><span class="c1">#     .. plot::</span>
<span class="linenos">1218</span><span class="c1">#</span>
<span class="linenos">1219</span><span class="c1">#         import numpy as np</span>
<span class="linenos">1220</span><span class="c1">#         import matplotlib.pyplot as plt</span>
<span class="linenos">1221</span><span class="c1">#         import pyxu.opt.solver as pysol</span>
<span class="linenos">1222</span><span class="c1">#         import pyxu.abc.solver as pysolver</span>
<span class="linenos">1223</span><span class="c1">#         import pyxu.opt.stop as pystop</span>
<span class="linenos">1224</span><span class="c1">#         import src.diffusion_ops.operator as diffop</span>
<span class="linenos">1225</span><span class="c1">#         import skimage as skim</span>
<span class="linenos">1226</span><span class="c1">#</span>
<span class="linenos">1227</span><span class="c1">#         # Import RGB image</span>
<span class="linenos">1228</span><span class="c1">#         image = skim.data.cat().astype(float)</span>
<span class="linenos">1229</span><span class="c1">#         print(image.shape) #(300, 451, 3)</span>
<span class="linenos">1230</span><span class="c1">#         # move color-stacking axis to front (needed for pyxu stacking convention)</span>
<span class="linenos">1231</span><span class="c1">#         image = np.moveaxis(image, 2, 0)</span>
<span class="linenos">1232</span><span class="c1">#         print(image.shape) #(3, 300, 451)</span>
<span class="linenos">1233</span><span class="c1">#         # Instantiate diffusion operator</span>
<span class="linenos">1234</span><span class="c1">#         coh_enh_diffop = diffop.AnisCoherenceEnhancingDiffusionOp(dim_shape=(300, 451), nchannels=3, alpha=1e-3, m=1)</span>
<span class="linenos">1235</span><span class="c1">#         # Define PGD solver, with stopping criterion and starting point x0</span>
<span class="linenos">1236</span><span class="c1">#         stop_crit = pystop.MaxIter(n=100)</span>
<span class="linenos">1237</span><span class="c1">#         x0 = image.reshape(1,-1)</span>
<span class="linenos">1238</span><span class="c1">#         # Perform 100 gradient flow iterations starting from x0</span>
<span class="linenos">1239</span><span class="c1">#         PGD = pysol.PGD(f = coh_enh_diffop, show_progress=False, verbosity=100)</span>
<span class="linenos">1240</span><span class="c1">#         PGD.fit(**dict(mode=pysolver.SolverMode.BLOCK, x0=x0, stop_crit=stop_crit,</span>
<span class="linenos">1241</span><span class="c1">#                        tau=2/coh_enh_diffop.diff_lipschitz))</span>
<span class="linenos">1242</span><span class="c1">#         coh_enhanced_image = PGD.solution()</span>
<span class="linenos">1243</span><span class="c1">#         # Reshape images for plotting.</span>
<span class="linenos">1244</span><span class="c1">#         image = np.moveaxis(image, 0, 2)</span>
<span class="linenos">1245</span><span class="c1">#         coh_enhanced_image = np.moveaxis(coh_enhanced_image.reshape(3, 300, 451), 0, 2)</span>
<span class="linenos">1246</span><span class="c1">#         # Plot</span>
<span class="linenos">1247</span><span class="c1">#         fig, ax = plt.subplots(1,2,figsize=(10,5))</span>
<span class="linenos">1248</span><span class="c1">#         ax[0].imshow(image.astype(int))</span>
<span class="linenos">1249</span><span class="c1">#         ax[0].set_title(&quot;Image&quot;, fontsize=15)</span>
<span class="linenos">1250</span><span class="c1">#         ax[0].axis(&#39;off&#39;)</span>
<span class="linenos">1251</span><span class="c1">#         ax[1].imshow(coh_enhanced_image.astype(int))</span>
<span class="linenos">1252</span><span class="c1">#         ax[1].set_title(&quot;100 iterations Coherence-Enhancing&quot;, fontsize=15)</span>
<span class="linenos">1253</span><span class="c1">#         ax[1].axis(&#39;off&#39;)</span>
<span class="linenos">1254</span><span class="c1">#</span>
<span class="linenos">1255</span><span class="c1">#     &quot;&quot;&quot;</span>
<span class="linenos">1256</span><span class="c1">#</span>
<span class="linenos">1257</span><span class="c1">#     def __init__(</span>
<span class="linenos">1258</span><span class="c1">#         self,</span>
<span class="linenos">1259</span><span class="c1">#         dim_shape: pyct.NDArrayShape,</span>
<span class="linenos">1260</span><span class="c1">#         freezing_arr_grad: pyct.NDArray,</span>
<span class="linenos">1261</span><span class="c1">#         extra_term: bool = True,</span>
<span class="linenos">1262</span><span class="c1">#         beta: pyct.Real = 1,</span>
<span class="linenos">1263</span><span class="c1">#         clipping_value: pyct.Real = 1e-5,</span>
<span class="linenos">1264</span><span class="c1">#         sigma_gd_st: pyct.Real = 1,</span>
<span class="linenos">1265</span><span class="c1">#         alpha: pyct.Real = 0.1,</span>
<span class="linenos">1266</span><span class="c1">#         sampling: typ.Union[pyct.Real, cabc.Sequence[pyct.Real, ...]] = 1,</span>
<span class="linenos">1267</span><span class="c1">#         diff_method_struct_tens: str = &quot;fd&quot;,</span>
<span class="linenos">1268</span><span class="c1">#     ):</span>
<span class="linenos">1269</span><span class="c1">#         # Needs to be revisited and adjusted to new changes in shapes etc. also, very interesting, because we want to implement</span>
<span class="linenos">1270</span><span class="c1">#         # approach shown here by default for all diffusion ops, so we should carefully consider this</span>
<span class="linenos">1271</span><span class="c1">#</span>
<span class="linenos">1272</span><span class="c1">#         # instantiate custom gradient operator, obtained projecting actual gradient along the structure tensor&#39;s eigendirections</span>
<span class="linenos">1273</span><span class="c1">#         # define non-oriented gradient matrix of shape (2N, N)</span>
<span class="linenos">1274</span><span class="c1">#         Dx = - np.diag(np.ones(dim_shape[0])) + np.diag(np.ones(dim_shape[0] - 1), 1)</span>
<span class="linenos">1275</span><span class="c1">#         Dx[-1, -1] = 0  # symmetric boundary conditions, no flux</span>
<span class="linenos">1276</span><span class="c1">#         Dy = - np.diag(np.ones(dim_shape[1])) + np.diag(np.ones(dim_shape[1] - 1), 1)</span>
<span class="linenos">1277</span><span class="c1">#         Dy[-1, -1] = 0  # symmetric boundary conditions, no flux</span>
<span class="linenos">1278</span><span class="c1">#         # define gradient matrix</span>
<span class="linenos">1279</span><span class="c1">#         D = np.vstack((np.kron(Dx, np.eye(dim_shape[1])), np.kron(np.eye(dim_shape[0]), Dy)))</span>
<span class="linenos">1280</span><span class="c1">#         # instantiate helper reg_fct_matrixfree to access to its methods</span>
<span class="linenos">1281</span><span class="c1">#         reg_fct_matrixfree = AnisDiffusionOp(dim_shape=dim_shape,</span>
<span class="linenos">1282</span><span class="c1">#                                                   alpha=alpha,</span>
<span class="linenos">1283</span><span class="c1">#                                                   sigma_gd_st=sigma_gd_st,</span>
<span class="linenos">1284</span><span class="c1">#                                                   sampling=sampling,</span>
<span class="linenos">1285</span><span class="c1">#                                                   diff_method_struct_tens=diff_method_struct_tens)</span>
<span class="linenos">1286</span><span class="c1">#         reg_fct_matrixfree._op.diffusion_coefficient.alpha = alpha</span>
<span class="linenos">1287</span><span class="c1">#         # returns eigenvectors u of shape (N, 2, 2), eigenvalues e of shape (N, 2)</span>
<span class="linenos">1288</span><span class="c1">#         u, e = reg_fct_matrixfree._op.diffusion_coefficient._eigendecompose_struct_tensor(freezing_arr_grad.reshape(1, -1))</span>
<span class="linenos">1289</span><span class="c1">#         # returns lambdas of shape (N, 2)</span>
<span class="linenos">1290</span><span class="c1">#         lambdas = reg_fct_matrixfree._op.diffusion_coefficient._compute_intensities(e)</span>
<span class="linenos">1291</span><span class="c1">#         lambdas = np.sqrt(lambdas)</span>
<span class="linenos">1292</span><span class="c1">#         # assemble coefficients w_coeffs of shape (2N, 1) to obtain oriented gradient</span>
<span class="linenos">1293</span><span class="c1">#         w_coeffs_e1 = (lambdas[:, 0] * u[:, :, 0]).flatten(order=&#39;F&#39;)</span>
<span class="linenos">1294</span><span class="c1">#         w_coeffs_e2 = (lambdas[:, 1] * u[:, :, 1]).flatten(order=&#39;F&#39;)</span>
<span class="linenos">1295</span><span class="c1">#         # compute oriented gradient matrices of shape (2N, N)</span>
<span class="linenos">1296</span><span class="c1">#         oriented_gradient_e1 = w_coeffs_e1 * D</span>
<span class="linenos">1297</span><span class="c1">#         oriented_gradient_e2 = w_coeffs_e2 * D</span>
<span class="linenos">1298</span><span class="c1">#         # assemble oriented gradient matrix by summing the two subblocks</span>
<span class="linenos">1299</span><span class="c1">#         N = np.prod(dim_shape)</span>
<span class="linenos">1300</span><span class="c1">#         oriented_gradient_matrix = np.vstack((oriented_gradient_e1[:N, :] + oriented_gradient_e1[N:, :],</span>
<span class="linenos">1301</span><span class="c1">#                                               oriented_gradient_e2[:N, :] + oriented_gradient_e2[N:, :]))</span>
<span class="linenos">1302</span><span class="c1">#         # instantiate gradient operator</span>
<span class="linenos">1303</span><span class="c1">#         gradient = pxa.LinOp.from_array(A=sp.csr_matrix(oriented_gradient_matrix))</span>
<span class="linenos">1304</span><span class="c1">#</span>
<span class="linenos">1305</span><span class="c1">#         # instantiate mfi_diffusion coeff</span>
<span class="linenos">1306</span><span class="c1">#         mfi_diffusion_coeff = DiffusionCoeffIsotropic(</span>
<span class="linenos">1307</span><span class="c1">#             dim_shape=dim_shape, diffusivity=MfiDiffusivity(dim_shape=dim_shape, beta=beta, clipping_value=clipping_value)</span>
<span class="linenos">1308</span><span class="c1">#         )</span>
<span class="linenos">1309</span><span class="c1">#         if extra_term:</span>
<span class="linenos">1310</span><span class="c1">#             mfi_extra_term = MfiExtraTerm(dim_shape=dim_shape, gradient=gradient, beta=beta, clipping_value=clipping_value)</span>
<span class="linenos">1311</span><span class="c1">#             super().__init__(</span>
<span class="linenos">1312</span><span class="c1">#                 dim_shape, gradient=gradient, diffusion_coefficient=mfi_diffusion_coeff, extra_diffusion_term=mfi_extra_term</span>
<span class="linenos">1313</span><span class="c1">#             )</span>
<span class="linenos">1314</span><span class="c1">#         else:</span>
<span class="linenos">1315</span><span class="c1">#             super().__init__(</span>
<span class="linenos">1316</span><span class="c1">#                 dim_shape, gradient=gradient, diffusion_coefficient=mfi_diffusion_coeff)</span>
<span class="linenos">1317</span><span class="c1">#         # initialize lipschitz constants. should this be done instead inside _DiffusionOp.__init__ ??</span>
<span class="linenos">1318</span><span class="c1">#         self.diff_lipschitz = gradient.lipschitz ** 2</span>
<span class="linenos">1319</span><span class="c1">#         if extra_term:</span>
<span class="linenos">1320</span><span class="c1">#             self.diff_lipschitz *= 2</span>
<span class="linenos">1321</span><span class="c1">#</span>
<span class="linenos">1322</span><span class="c1">#     #@pycrt.enforce_precision(i=&quot;arr&quot;)</span>
<span class="linenos">1323</span><span class="c1">#     @pycu.vectorize(&quot;arr&quot;)</span>
<span class="linenos">1324</span><span class="c1">#     def apply(self, arr: pyct.NDArray) -&gt; pyct.Real:</span>
<span class="linenos">1325</span><span class="c1">#         if self.extra_diffusion_term is not None:</span>
<span class="linenos">1326</span><span class="c1">#             xp = pycu.get_array_module(arr)</span>
<span class="linenos">1327</span><span class="c1">#             y = self._compute_divergence_term(arr)</span>
<span class="linenos">1328</span><span class="c1">#             arr = arr.reshape(1, -1)</span>
<span class="linenos">1329</span><span class="c1">#             return xp.dot(arr, y.T) / 2</span>
<span class="linenos">1330</span><span class="c1">#         else:</span>
<span class="linenos">1331</span><span class="c1">#             raise RuntimeError(&quot;&#39;apply()&#39; method not defined for AnisMfiDiffusionOp with no MfiExtraTerm: no underlying variational intepretation&quot;)</span>
</pre></div>

                </article>
              
              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
<div id="searchbox"></div></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">
  <p class="copyright">
    
       Copyright 2025, Daniele Hamm &lt;daniele.hamm@epfl.ch&gt;.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">
  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.4.7.
    <br/>
  </p>
</div>
      
        <div class="footer-item"><p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.13.3.
</p></div>
      
    </div>
  
  
    <div class="footer-items__end">
      
        <div class="footer-item"><p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.13.3.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>